{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudogroup-labels by splitting training set\n",
    "The idea is that naive ERM model will have an inherit bias given certain training set and one way to figure out such a bias is through using a validation set (i.e. the initial model would fail on these validation points while having 100% accuracy on the training set). \n",
    "Hence, the idea is to partition the training data into two parts: first part is used to train the the initial model (with fraction f of the training data) while the second part is used to \"retrain\" the model (either fine-tuning the last layer or fine-tuning the entire model or retraining the entire model). \n",
    "Doing so will enable:\n",
    "1. If the initial features are good, then finetuning the last model (i.e. the linear classifier on top of these features) using the pseudogroup-labelled second dataset will hopefully give us a much better classifier rather than the initial biased classifier that might use certain spurious features. There is evidence for this behavior in the long-tail literature (e.g. tau-norm)\n",
    "2. If the features are not that good, then retraining the entire model (either with fresh initialization or on top of the previous intialization) using methods that incorporate these pseudolabels will hopefully help the model obtain results close to when we have the true labels. \n",
    "    - Retraining the entire model might require a much higher sample complexity than just finetuning the last layer and there's an obvious tradeoff between these methods here. \n",
    "\n",
    "The goal here is to reduce the naive ERM model's spurious correlation. There might be further spurious correlations but the assumption is that the naive ERM model's spurious correlation might be the most obvious one that datasets in this worst-group-error area tends to focus on. To solve this in general would be to perfectly model the data distribution, and that seems much more difficult (domain generalization). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "This method, unlike many existing methods in the literature, aims to improve worst-group error by generating pseudogroup labels without real group labels (so that we can perform model selection... also we can have a long discussion on what \"real group labels\" mean) while minimizing the amount of hyperparameters required for proper implementation. \n",
    "We perform the following steps:\n",
    "1. Partition the training set into part1 and part2 with $f$ and $(1-f)$ proportions, respectively.\n",
    "2. Train an initial ERM model $I$ to convergence (either 100% accuracy or doesn't improve) on part1 of the training set.\n",
    "3. Evaluate part2 of the train set on $I$. For each example $(x,y) \\in$ part2, record $(x,y,s)$ where $s=1[I(x)=y]$ is the status of whether $I$ correctly classifies $x$ or not. \n",
    "    - Generate pseudogroup labels for examples in part2: for every $(x,y)$ in part2, the group label is $(y,s)$. This implicitly implies that the algorithm is partitioning every label into two groups. This is the case with popular \"pseudogroup-generating\" algorithms like JTT, GEORGE, EIIL, etc.\n",
    "4. Retrain model $I$ to $I'$ using the pseudogroup labels by either fine-tuning the last layer, fine-tuning the model $I$, or train a new model entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "## 1. Partitioning the train set into part1 and part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thiennguyen/research/pseudogroups/split_pgl\n"
     ]
    }
   ],
   "source": [
    "%cd ~/research/pseudogroups/split_pgl\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import dataset_attributes, shift_types, prepare_data, log_data\n",
    "from utils import set_seed, Logger, CSVBatchLogger, log_args, get_model, hinge_loss\n",
    "from notebooks.example_args import MyCUBArgs\n",
    "import torch \n",
    "from data import dro_dataset\n",
    "import wandb, os\n",
    "from train import train\n",
    "from data.folds import Subset, ConcatDataset\n",
    "\n",
    "mainargs = MyCUBArgs(wandb=False,\n",
    "                     seed=0,\n",
    "                     show_progress=False,\n",
    "                     project_name='')  # default gpu = 0\n",
    "part1_args = mainargs.part1_args\n",
    "part2_args = mainargs.part2_args\n",
    "args = part1_args\n",
    "set_seed(args.seed)\n",
    "\n",
    "def split_data(dataset, part1_proportion=0.5, seed=None):\n",
    "    \"\"\"\n",
    "        Split data into 2 parts given a ratio.\n",
    "    \"\"\"\n",
    "    random = np.random.RandomState(seed)\n",
    "    n_exs = len(dataset)\n",
    "    n_part1 = int(n_exs*part1_proportion)\n",
    "    # n_part2 = n_exs - n_part1\n",
    "    if type(dataset) == Subset:  # note that this Subset is data.folds.Subset\n",
    "        idxs = np.random.permutation(dataset.indices)\n",
    "        data = dataset.dataset\n",
    "    else:  # this is not a Subset i.e. just an ordinary dataset\n",
    "        idxs = np.random.permutation(np.arange(len(dataset)))\n",
    "        data = dataset\n",
    "    part1, part2 = Subset(data, idxs[:n_part1]), Subset(data, idxs[n_part1:])  # this is not torch subset\n",
    "    return part1, part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading './cub/data/waterbird_complete95_forest2water2/metadata.csv'\n"
     ]
    }
   ],
   "source": [
    "## Function given dataset and fraction f (is this implemented already?)\n",
    "# first load the train set\n",
    "train_data, val_data, test_data = prepare_data(args, train=True)\n",
    "# then split it into part1 containing f*n examples of trainset and part2 containing the rest\n",
    "part1, part2 = split_data(train_data.dataset, part1_proportion=0.5, seed=args.seed)\n",
    "\n",
    "part1_data = dro_dataset.DRODataset(\n",
    "    part1,\n",
    "    process_item_fn=None,\n",
    "    n_groups=train_data.n_groups,\n",
    "    n_classes=train_data.n_classes,\n",
    "    group_str_fn=train_data.group_str)\n",
    "\n",
    "part2_data = dro_dataset.DRODataset(\n",
    "    part2,\n",
    "    process_item_fn=None,\n",
    "    n_groups=train_data.n_groups,\n",
    "    n_classes=train_data.n_classes,\n",
    "    group_str_fn=train_data.group_str)\n",
    "\n",
    "loader_kwargs = {\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"num_workers\": 4,\n",
    "        \"pin_memory\": True,\n",
    "    }\n",
    "part1_loader = dro_dataset.get_loader(part1_data,\n",
    "                                      train=True,\n",
    "                                      reweight_groups=None,\n",
    "                                      **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from utils import get_subsampled_indices\n",
    "indices = get_subsampled_indices(part2_data)\n",
    "for i in indices:\n",
    "    print(part2_data[i][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mydir = '/root1/second/third'\n",
    "test = os.path.basename(os.path.dirname(mydir))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the initial ERM model on part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/SPGL_proportion0.5_epochs51_lr0.001_weightdecay0.0001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3587441/479567325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m## Initialize logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pseudogroups/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pseudogroups/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/SPGL_proportion0.5_epochs51_lr0.001_weightdecay0.0001'"
     ]
    }
   ],
   "source": [
    "\"\"\"this would be in run_expt\"\"\"\n",
    "RUN_TEST = False\n",
    "mode = 'w'\n",
    "args.wandb = False\n",
    "if args.wandb:\n",
    "    run = wandb.init(project=f\"{args.project_name}_{args.dataset}\")\n",
    "    wandb.config.update(args)\n",
    "    \n",
    "## Initialize logs\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "logger = Logger(os.path.join(args.log_dir, \"log.txt\"), 'w')\n",
    "# Record args\n",
    "log_args(args, logger)\n",
    "# set_seed(args.seed)\n",
    "\n",
    "# get loader and run train ERM\n",
    "loader_kwargs = {\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"num_workers\": 4,\n",
    "        \"pin_memory\": True,\n",
    "    }\n",
    "part1_loader = dro_dataset.get_loader(part1_data,\n",
    "                                      train=True,\n",
    "                                      reweight_groups=None,\n",
    "                                      **loader_kwargs)\n",
    "val_loader = dro_dataset.get_loader(val_data,\n",
    "                                    train=False,\n",
    "                                    reweight_groups=None,\n",
    "                                    **loader_kwargs)\n",
    "\n",
    "data = {}\n",
    "data[\"train_data\"] = part1_data\n",
    "data[\"train_loader\"] = part1_loader  # we train using  part1 \n",
    "data[\"val_data\"] = val_data\n",
    "data[\"val_loader\"] = val_loader\n",
    "\n",
    "data[\"test_data\"] = test_data\n",
    "data[\"test_loader\"] = None\n",
    "\n",
    "train_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"train.csv\"),\n",
    "                                  train_data.n_groups,\n",
    "                                  mode=mode)\n",
    "val_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"val.csv\"),\n",
    "                                val_data.n_groups,\n",
    "                                mode=mode)\n",
    "test_csv_logger = None\n",
    "\n",
    "if RUN_TEST:\n",
    "    test_loader = dro_dataset.get_loader(test_data,\n",
    "                                     train=False,\n",
    "                                     reweight_groups=None,\n",
    "                                     **loader_kwargs)\n",
    "    data[\"test_loader\"] = test_loader\n",
    "    test_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"test.csv\"),\n",
    "                                 test_data.n_groups,\n",
    "                                 mode=mode)\n",
    "\n",
    "n_classes = train_data.n_classes\n",
    "\n",
    "log_data(data, logger)\n",
    "logger.flush()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [0]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_0.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.318  \n",
      "Average sample loss: 0.316  \n",
      "Average acc: 0.875  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.170  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.558  exp loss = 0.785  adjusted loss = 0.785  adv prob = 0.250000   acc = 0.705\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 1.396  exp loss = 1.349  adjusted loss = 1.349  adv prob = 0.250000   acc = 0.107\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.702  exp loss = 0.359  adjusted loss = 0.359  adv prob = 0.250000   acc = 0.560\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_0.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.543  \n",
      "Average sample loss: 0.539  \n",
      "Average acc: 0.736  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.043  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.996\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.697  exp loss = 0.665  adjusted loss = 0.665  adv prob = 0.250000   acc = 0.601\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.978  exp loss = 2.077  adjusted loss = 2.077  adv prob = 0.250000   acc = 0.128\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.327  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.902\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_0.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [1]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_1.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.119  \n",
      "Average sample loss: 0.119  \n",
      "Average acc: 0.961  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.034  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.999\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.696  exp loss = 0.616  adjusted loss = 0.616  adv prob = 0.250000   acc = 0.625\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 1.335  exp loss = 1.291  adjusted loss = 1.291  adv prob = 0.250000   acc = 0.429\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.236  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.920\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_1.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.490  \n",
      "Average sample loss: 0.487  \n",
      "Average acc: 0.775  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.698  exp loss = 0.683  adjusted loss = 0.683  adv prob = 0.250000   acc = 0.637\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.674  exp loss = 1.793  adjusted loss = 1.793  adv prob = 0.250000   acc = 0.301\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.186  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_1.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [2]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_2.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.074  \n",
      "Average sample loss: 0.075  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.027  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.999\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.373  exp loss = 0.430  adjusted loss = 0.430  adv prob = 0.250000   acc = 0.841\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.770  exp loss = 0.896  adjusted loss = 0.896  adv prob = 0.250000   acc = 0.679\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.143  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.955\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_2.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.475  \n",
      "Average sample loss: 0.472  \n",
      "Average acc: 0.795  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.035  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.746  exp loss = 0.746  adjusted loss = 0.746  adv prob = 0.250000   acc = 0.646\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.409  exp loss = 1.516  adjusted loss = 1.516  adv prob = 0.250000   acc = 0.451\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.138  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_2.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [3]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_3.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.051  \n",
      "Average sample loss: 0.051  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.020  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.999\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.241  exp loss = 0.391  adjusted loss = 0.391  adv prob = 0.250000   acc = 0.932\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.512  exp loss = 0.489  adjusted loss = 0.489  adv prob = 0.250000   acc = 0.750\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.098  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.966\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_3.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.500  \n",
      "Average sample loss: 0.497  \n",
      "Average acc: 0.795  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.032  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.827  exp loss = 0.830  adjusted loss = 0.830  adv prob = 0.250000   acc = 0.637\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.375  exp loss = 1.492  adjusted loss = 1.492  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.121  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_3.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [4]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_4.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.031  \n",
      "Average sample loss: 0.032  \n",
      "Average acc: 0.995  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.013  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.126  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.337  exp loss = 0.309  adjusted loss = 0.309  adv prob = 0.250000   acc = 0.857\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.058  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.987\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_4.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.480  \n",
      "Average sample loss: 0.476  \n",
      "Average acc: 0.813  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.711  exp loss = 0.711  adjusted loss = 0.711  adv prob = 0.250000   acc = 0.693\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.617  exp loss = 1.783  adjusted loss = 1.783  adv prob = 0.250000   acc = 0.451\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.143  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_4.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [5]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_5.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.023  \n",
      "Average sample loss: 0.023  \n",
      "Average acc: 0.997  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.074  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.266  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.893\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.046  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.993\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_5.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.502  \n",
      "Average sample loss: 0.498  \n",
      "Average acc: 0.811  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.781  exp loss = 0.782  adjusted loss = 0.782  adv prob = 0.250000   acc = 0.682\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.579  exp loss = 1.727  adjusted loss = 1.727  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.132  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_5.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [6]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_6.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.015  \n",
      "Average sample loss: 0.015  \n",
      "Average acc: 0.999  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.054  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.219  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.929\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.025  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.998\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_6.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.508  \n",
      "Average sample loss: 0.504  \n",
      "Average acc: 0.815  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.758  exp loss = 0.754  adjusted loss = 0.754  adv prob = 0.250000   acc = 0.693\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.717  exp loss = 1.891  adjusted loss = 1.891  adv prob = 0.250000   acc = 0.466\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.144  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_6.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [7]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_7.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.011  \n",
      "Average sample loss: 0.011  \n",
      "Average acc: 0.999  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.036  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.101  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.929\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.021  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.998\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_7.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.562  \n",
      "Average sample loss: 0.558  \n",
      "Average acc: 0.798  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.023  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.938  exp loss = 0.941  adjusted loss = 0.941  adv prob = 0.250000   acc = 0.642\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.574  exp loss = 1.698  adjusted loss = 1.698  adv prob = 0.250000   acc = 0.496\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.122  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_7.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [8]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_8.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.009  \n",
      "Average sample loss: 0.009  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.028  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.078  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.998\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_8.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.549  \n",
      "Average sample loss: 0.546  \n",
      "Average acc: 0.805  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.885  exp loss = 0.888  adjusted loss = 0.888  adv prob = 0.250000   acc = 0.659\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.651  exp loss = 1.803  adjusted loss = 1.803  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.130  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_8.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [9]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_9.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.007  \n",
      "Average sample loss: 0.007  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.017  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.077  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_9.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.544  \n",
      "Average sample loss: 0.540  \n",
      "Average acc: 0.817  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.838  exp loss = 0.837  adjusted loss = 0.837  adv prob = 0.250000   acc = 0.695\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.773  exp loss = 1.930  adjusted loss = 1.930  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.141  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_9.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [10]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_10.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.006  \n",
      "Average sample loss: 0.006  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.015  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.069  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_10.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.559  \n",
      "Average sample loss: 0.555  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.865  exp loss = 0.868  adjusted loss = 0.868  adv prob = 0.250000   acc = 0.680\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.803  exp loss = 1.965  adjusted loss = 1.965  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.143  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_10.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [11]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_11.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.005  \n",
      "Average sample loss: 0.005  \n",
      "Average acc: 0.999  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.062  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_11.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.586  \n",
      "Average sample loss: 0.582  \n",
      "Average acc: 0.805  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.937  exp loss = 0.937  adjusted loss = 0.937  adv prob = 0.250000   acc = 0.661\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.797  exp loss = 1.951  adjusted loss = 1.951  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.138  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_11.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [12]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_12.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.005  \n",
      "Average sample loss: 0.005  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.052  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_12.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.576  \n",
      "Average sample loss: 0.572  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.892  exp loss = 0.892  adjusted loss = 0.892  adv prob = 0.250000   acc = 0.682\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.862  exp loss = 2.036  adjusted loss = 2.036  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.148  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_12.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [13]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_13.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.005  \n",
      "Average sample loss: 0.005  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.020  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.054  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_13.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.590  \n",
      "Average sample loss: 0.586  \n",
      "Average acc: 0.804  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.017  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.945  exp loss = 0.942  adjusted loss = 0.942  adv prob = 0.250000   acc = 0.659\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.807  exp loss = 1.953  adjusted loss = 1.953  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.139  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_13.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [14]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_14.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.003  \n",
      "Average sample loss: 0.003  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.009  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.030  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_14.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.622  \n",
      "Average sample loss: 0.619  \n",
      "Average acc: 0.797  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.020  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.051  exp loss = 1.051  adjusted loss = 1.051  adv prob = 0.250000   acc = 0.635\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.731  exp loss = 1.874  adjusted loss = 1.874  adv prob = 0.250000   acc = 0.511\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.128  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_14.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [15]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_15.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.004  \n",
      "Average sample loss: 0.004  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.008  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.027  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_15.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.614  \n",
      "Average sample loss: 0.610  \n",
      "Average acc: 0.807  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.007  exp loss = 1.011  adjusted loss = 1.011  adv prob = 0.250000   acc = 0.657\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.808  exp loss = 1.960  adjusted loss = 1.960  adv prob = 0.250000   acc = 0.511\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.136  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_15.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [16]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_16.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.003  \n",
      "Average sample loss: 0.003  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.022  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_16.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.626  \n",
      "Average sample loss: 0.622  \n",
      "Average acc: 0.802  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.034  exp loss = 1.036  adjusted loss = 1.036  adv prob = 0.250000   acc = 0.648\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.823  exp loss = 1.960  adjusted loss = 1.960  adv prob = 0.250000   acc = 0.504\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.137  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_16.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [17]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_17.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.003  \n",
      "Average sample loss: 0.004  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.031  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.006  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_17.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.603  \n",
      "Average sample loss: 0.598  \n",
      "Average acc: 0.822  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.013  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.902  exp loss = 0.899  adjusted loss = 0.899  adv prob = 0.250000   acc = 0.712\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.071  exp loss = 2.276  adjusted loss = 2.276  adv prob = 0.250000   acc = 0.466\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.158  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.955\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_17.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [18]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_18.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.017  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_18.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.636  \n",
      "Average sample loss: 0.632  \n",
      "Average acc: 0.799  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.017  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.039  exp loss = 1.042  adjusted loss = 1.042  adv prob = 0.250000   acc = 0.648\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.898  exp loss = 2.047  adjusted loss = 2.047  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.139  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_18.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [19]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_19.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.003  \n",
      "Average sample loss: 0.003  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.017  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_19.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.636  \n",
      "Average sample loss: 0.632  \n",
      "Average acc: 0.801  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.048  exp loss = 1.050  adjusted loss = 1.050  adv prob = 0.250000   acc = 0.650\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.867  exp loss = 2.011  adjusted loss = 2.011  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.137  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_19.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [20]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_20.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.020  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_20.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.624  \n",
      "Average sample loss: 0.619  \n",
      "Average acc: 0.809  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.996  exp loss = 0.990  adjusted loss = 0.990  adv prob = 0.250000   acc = 0.670\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.937  exp loss = 2.094  adjusted loss = 2.094  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.145  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_20.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [21]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_21.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.005  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_21.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.618  \n",
      "Average sample loss: 0.613  \n",
      "Average acc: 0.817  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.963  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.689\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.994  exp loss = 2.163  adjusted loss = 2.163  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.149  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_21.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [22]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_22.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_22.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.613  \n",
      "Average sample loss: 0.608  \n",
      "Average acc: 0.816  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.954  exp loss = 0.953  adjusted loss = 0.953  adv prob = 0.250000   acc = 0.689\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.980  exp loss = 2.155  adjusted loss = 2.155  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.152  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_22.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [23]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_23.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.018  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_23.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.669  \n",
      "Average sample loss: 0.664  \n",
      "Average acc: 0.797  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.126  exp loss = 1.122  adjusted loss = 1.122  adv prob = 0.250000   acc = 0.635\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.881  exp loss = 2.021  adjusted loss = 2.021  adv prob = 0.250000   acc = 0.511\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.134  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_23.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [24]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_24.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.009  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_24.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.668  \n",
      "Average sample loss: 0.663  \n",
      "Average acc: 0.802  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.129  exp loss = 1.130  adjusted loss = 1.130  adv prob = 0.250000   acc = 0.642\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.861  exp loss = 1.988  adjusted loss = 1.988  adv prob = 0.250000   acc = 0.534\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.136  exp loss = 0.112  adjusted loss = 0.112  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_24.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [25]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_25.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_25.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.659  \n",
      "Average sample loss: 0.654  \n",
      "Average acc: 0.802  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.019  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.084  exp loss = 1.079  adjusted loss = 1.079  adv prob = 0.250000   acc = 0.652\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.935  exp loss = 2.069  adjusted loss = 2.069  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.141  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_25.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [26]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_26.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.002  \n",
      "Average sample loss: 0.002  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_26.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.627  \n",
      "Average sample loss: 0.622  \n",
      "Average acc: 0.822  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.014  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.946  exp loss = 0.937  adjusted loss = 0.937  adv prob = 0.250000   acc = 0.710\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.126  exp loss = 2.310  adjusted loss = 2.310  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.165  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_26.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [27]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_27.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.011  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_27.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.651  \n",
      "Average sample loss: 0.646  \n",
      "Average acc: 0.810  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.015  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.678\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.099  exp loss = 2.264  adjusted loss = 2.264  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.157  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_27.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [28]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_28.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_28.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.656  \n",
      "Average sample loss: 0.651  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.042  exp loss = 1.041  adjusted loss = 1.041  adv prob = 0.250000   acc = 0.682\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.053  exp loss = 2.217  adjusted loss = 2.217  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.153  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_28.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [29]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_29.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_29.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.668  \n",
      "Average sample loss: 0.664  \n",
      "Average acc: 0.806  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.017  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.071  exp loss = 1.063  adjusted loss = 1.063  adv prob = 0.250000   acc = 0.665\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.061  exp loss = 2.209  adjusted loss = 2.209  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.152  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_29.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [30]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_30.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_30.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.717  \n",
      "Average sample loss: 0.713  \n",
      "Average acc: 0.791  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.022  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.258  exp loss = 1.263  adjusted loss = 1.263  adv prob = 0.250000   acc = 0.614\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.845  exp loss = 1.925  adjusted loss = 1.925  adv prob = 0.250000   acc = 0.526\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.134  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 0.977\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_30.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [31]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_31.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_31.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.691  \n",
      "Average sample loss: 0.687  \n",
      "Average acc: 0.803  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.019  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.162  exp loss = 1.163  adjusted loss = 1.163  adv prob = 0.250000   acc = 0.646\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.952  exp loss = 2.068  adjusted loss = 2.068  adv prob = 0.250000   acc = 0.526\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.143  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_31.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [32]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_32.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_32.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.672  \n",
      "Average sample loss: 0.667  \n",
      "Average acc: 0.810  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.076  exp loss = 1.071  adjusted loss = 1.071  adv prob = 0.250000   acc = 0.674\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.073  exp loss = 2.213  adjusted loss = 2.213  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.153  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_32.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [33]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_33.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.009  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_33.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.664  \n",
      "Average sample loss: 0.659  \n",
      "Average acc: 0.808  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.053  exp loss = 1.047  adjusted loss = 1.047  adv prob = 0.250000   acc = 0.667\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.084  exp loss = 2.232  adjusted loss = 2.232  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.156  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_33.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [34]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_34.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_34.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.689  \n",
      "Average sample loss: 0.685  \n",
      "Average acc: 0.803  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.145  exp loss = 1.141  adjusted loss = 1.141  adv prob = 0.250000   acc = 0.652\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.996  exp loss = 2.122  adjusted loss = 2.122  adv prob = 0.250000   acc = 0.504\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.146  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_34.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [35]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_35.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_35.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.661  \n",
      "Average sample loss: 0.656  \n",
      "Average acc: 0.818  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.024  exp loss = 1.015  adjusted loss = 1.015  adv prob = 0.250000   acc = 0.695\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.163  exp loss = 2.324  adjusted loss = 2.324  adv prob = 0.250000   acc = 0.481\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.161  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_35.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [36]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_36.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_36.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.672  \n",
      "Average sample loss: 0.667  \n",
      "Average acc: 0.818  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.097  exp loss = 1.096  adjusted loss = 1.096  adv prob = 0.250000   acc = 0.685\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.997  exp loss = 2.104  adjusted loss = 2.104  adv prob = 0.250000   acc = 0.526\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.153  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_36.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [37]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_37.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_37.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.685  \n",
      "Average sample loss: 0.680  \n",
      "Average acc: 0.810  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.123  exp loss = 1.116  adjusted loss = 1.116  adv prob = 0.250000   acc = 0.665\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.021  exp loss = 2.145  adjusted loss = 2.145  adv prob = 0.250000   acc = 0.519\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.152  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_37.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [38]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_38.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.010  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_38.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.647  \n",
      "Average sample loss: 0.642  \n",
      "Average acc: 0.824  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.013  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.969  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.715\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.222  exp loss = 2.397  adjusted loss = 2.397  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.169  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_38.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [39]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_39.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.006  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_39.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.686  \n",
      "Average sample loss: 0.681  \n",
      "Average acc: 0.808  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.116  exp loss = 1.114  adjusted loss = 1.114  adv prob = 0.250000   acc = 0.667\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.064  exp loss = 2.187  adjusted loss = 2.187  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.153  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_39.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [40]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_40.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.006  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_40.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.709  \n",
      "Average sample loss: 0.705  \n",
      "Average acc: 0.802  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.019  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.192  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.644\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.006  exp loss = 2.130  adjusted loss = 2.130  adv prob = 0.250000   acc = 0.526\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.146  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_40.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [41]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_41.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_41.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.681  \n",
      "Average sample loss: 0.676  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.105  exp loss = 1.100  adjusted loss = 1.100  adv prob = 0.250000   acc = 0.670\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.052  exp loss = 2.186  adjusted loss = 2.186  adv prob = 0.250000   acc = 0.519\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.154  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.962\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_41.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [42]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_42.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_42.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.687  \n",
      "Average sample loss: 0.683  \n",
      "Average acc: 0.809  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.100  exp loss = 1.094  adjusted loss = 1.094  adv prob = 0.250000   acc = 0.670\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.134  exp loss = 2.287  adjusted loss = 2.287  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.155  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_42.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [43]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_43.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.011  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_43.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.728  \n",
      "Average sample loss: 0.723  \n",
      "Average acc: 0.797  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.021  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.266  exp loss = 1.260  adjusted loss = 1.260  adv prob = 0.250000   acc = 0.629\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.914  exp loss = 2.006  adjusted loss = 2.006  adv prob = 0.250000   acc = 0.534\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.138  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.977\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_43.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [44]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_44.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_44.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.692  \n",
      "Average sample loss: 0.687  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.017  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.120  exp loss = 1.111  adjusted loss = 1.111  adv prob = 0.250000   acc = 0.670\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.105  exp loss = 2.237  adjusted loss = 2.237  adv prob = 0.250000   acc = 0.511\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.154  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_44.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [45]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_45.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.006  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_45.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.642  \n",
      "Average sample loss: 0.637  \n",
      "Average acc: 0.832  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.011  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.920  exp loss = 0.903  adjusted loss = 0.903  adv prob = 0.250000   acc = 0.738\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.343  exp loss = 2.526  adjusted loss = 2.526  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.185  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_45.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [46]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_46.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_46.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.728  \n",
      "Average sample loss: 0.723  \n",
      "Average acc: 0.802  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.020  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.242  exp loss = 1.233  adjusted loss = 1.233  adv prob = 0.250000   acc = 0.642\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.994  exp loss = 2.105  adjusted loss = 2.105  adv prob = 0.250000   acc = 0.534\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.143  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_46.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [47]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_47.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_47.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.694  \n",
      "Average sample loss: 0.689  \n",
      "Average acc: 0.812  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.100  exp loss = 1.087  adjusted loss = 1.087  adv prob = 0.250000   acc = 0.678\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.189  exp loss = 2.335  adjusted loss = 2.335  adv prob = 0.250000   acc = 0.489\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.162  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.970\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_47.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [48]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_48.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_48.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.686  \n",
      "Average sample loss: 0.680  \n",
      "Average acc: 0.811  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.014  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.055  exp loss = 1.043  adjusted loss = 1.043  adv prob = 0.250000   acc = 0.682\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.267  exp loss = 2.448  adjusted loss = 2.448  adv prob = 0.250000   acc = 0.474\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.170  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.955\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_48.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [49]:\n",
      "Training:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_train_epoch_49.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.001  \n",
      "Average sample loss: 0.001  \n",
      "Average acc: 1.000  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1745]:\tloss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 88]:\tloss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 28]:\tloss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 536]:\tloss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000\n",
      "\n",
      "Validation:\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_val_epoch_49.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.692  \n",
      "Average sample loss: 0.687  \n",
      "Average acc: 0.813  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 1.086  exp loss = 1.071  adjusted loss = 1.071  adv prob = 0.250000   acc = 0.682\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 2.214  exp loss = 2.389  adjusted loss = 2.389  adv prob = 0.250000   acc = 0.496\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.167  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.955\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/model_outputs/output_test_epoch_49.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### INITIALIZE MODEL AND TRAIN ###\n",
    "resume = False  # not resuming yet. \n",
    "## Initialize model\n",
    "model = get_model(\n",
    "    model=args.model,\n",
    "    pretrained=not args.train_from_scratch,\n",
    "    resume=resume,\n",
    "    n_classes=train_data.n_classes,\n",
    "    dataset=args.dataset,\n",
    "    log_dir=args.log_dir,\n",
    ")\n",
    "if args.wandb:\n",
    "    wandb.watch(model)\n",
    "\n",
    "epoch_offset = 0\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    criterion,\n",
    "    data,\n",
    "    logger,\n",
    "    train_csv_logger,\n",
    "    val_csv_logger,\n",
    "    test_csv_logger,\n",
    "    args,\n",
    "    epoch_offset=epoch_offset,\n",
    "    csv_name=args.fold,\n",
    "    wandb=wandb if args.wandb else None,\n",
    ")\n",
    "\n",
    "train_csv_logger.close()\n",
    "val_csv_logger.close()\n",
    "if RUN_TEST:\n",
    "    test_csv_logger.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating part2 on the initial ERM model and generate pseudogroup labels for part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First evaluate part2 on initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_model.pth\t\t    output_train_epoch_64.csv  output_val_epoch_39.csv\r\n",
      "100_model.pth\t\t    output_train_epoch_65.csv  output_val_epoch_3.csv\r\n",
      "10_model.pth\t\t    output_train_epoch_66.csv  output_val_epoch_40.csv\r\n",
      "20_model.pth\t\t    output_train_epoch_67.csv  output_val_epoch_41.csv\r\n",
      "30_model.pth\t\t    output_train_epoch_68.csv  output_val_epoch_42.csv\r\n",
      "40_model.pth\t\t    output_train_epoch_69.csv  output_val_epoch_43.csv\r\n",
      "50_model.pth\t\t    output_train_epoch_6.csv   output_val_epoch_44.csv\r\n",
      "60_model.pth\t\t    output_train_epoch_70.csv  output_val_epoch_45.csv\r\n",
      "70_model.pth\t\t    output_train_epoch_71.csv  output_val_epoch_46.csv\r\n",
      "80_model.pth\t\t    output_train_epoch_72.csv  output_val_epoch_47.csv\r\n",
      "90_model.pth\t\t    output_train_epoch_73.csv  output_val_epoch_48.csv\r\n",
      "log.txt\t\t\t    output_train_epoch_74.csv  output_val_epoch_49.csv\r\n",
      "output_train_epoch_0.csv    output_train_epoch_75.csv  output_val_epoch_4.csv\r\n",
      "output_train_epoch_100.csv  output_train_epoch_76.csv  output_val_epoch_50.csv\r\n",
      "output_train_epoch_10.csv   output_train_epoch_77.csv  output_val_epoch_51.csv\r\n",
      "output_train_epoch_11.csv   output_train_epoch_78.csv  output_val_epoch_52.csv\r\n",
      "output_train_epoch_12.csv   output_train_epoch_79.csv  output_val_epoch_53.csv\r\n",
      "output_train_epoch_13.csv   output_train_epoch_7.csv   output_val_epoch_54.csv\r\n",
      "output_train_epoch_14.csv   output_train_epoch_80.csv  output_val_epoch_55.csv\r\n",
      "output_train_epoch_15.csv   output_train_epoch_81.csv  output_val_epoch_56.csv\r\n",
      "output_train_epoch_16.csv   output_train_epoch_82.csv  output_val_epoch_57.csv\r\n",
      "output_train_epoch_17.csv   output_train_epoch_83.csv  output_val_epoch_58.csv\r\n",
      "output_train_epoch_18.csv   output_train_epoch_84.csv  output_val_epoch_59.csv\r\n",
      "output_train_epoch_19.csv   output_train_epoch_85.csv  output_val_epoch_5.csv\r\n",
      "output_train_epoch_1.csv    output_train_epoch_86.csv  output_val_epoch_60.csv\r\n",
      "output_train_epoch_20.csv   output_train_epoch_87.csv  output_val_epoch_61.csv\r\n",
      "output_train_epoch_21.csv   output_train_epoch_88.csv  output_val_epoch_62.csv\r\n",
      "output_train_epoch_22.csv   output_train_epoch_89.csv  output_val_epoch_63.csv\r\n",
      "output_train_epoch_23.csv   output_train_epoch_8.csv   output_val_epoch_64.csv\r\n",
      "output_train_epoch_24.csv   output_train_epoch_90.csv  output_val_epoch_65.csv\r\n",
      "output_train_epoch_25.csv   output_train_epoch_91.csv  output_val_epoch_66.csv\r\n",
      "output_train_epoch_26.csv   output_train_epoch_92.csv  output_val_epoch_67.csv\r\n",
      "output_train_epoch_27.csv   output_train_epoch_93.csv  output_val_epoch_68.csv\r\n",
      "output_train_epoch_28.csv   output_train_epoch_94.csv  output_val_epoch_69.csv\r\n",
      "output_train_epoch_29.csv   output_train_epoch_95.csv  output_val_epoch_6.csv\r\n",
      "output_train_epoch_2.csv    output_train_epoch_96.csv  output_val_epoch_70.csv\r\n",
      "output_train_epoch_30.csv   output_train_epoch_97.csv  output_val_epoch_71.csv\r\n",
      "output_train_epoch_31.csv   output_train_epoch_98.csv  output_val_epoch_72.csv\r\n",
      "output_train_epoch_32.csv   output_train_epoch_99.csv  output_val_epoch_73.csv\r\n",
      "output_train_epoch_33.csv   output_train_epoch_9.csv   output_val_epoch_74.csv\r\n",
      "output_train_epoch_34.csv   output_val_epoch_0.csv     output_val_epoch_75.csv\r\n",
      "output_train_epoch_35.csv   output_val_epoch_100.csv   output_val_epoch_76.csv\r\n",
      "output_train_epoch_36.csv   output_val_epoch_10.csv    output_val_epoch_77.csv\r\n",
      "output_train_epoch_37.csv   output_val_epoch_11.csv    output_val_epoch_78.csv\r\n",
      "output_train_epoch_38.csv   output_val_epoch_12.csv    output_val_epoch_79.csv\r\n",
      "output_train_epoch_39.csv   output_val_epoch_13.csv    output_val_epoch_7.csv\r\n",
      "output_train_epoch_3.csv    output_val_epoch_14.csv    output_val_epoch_80.csv\r\n",
      "output_train_epoch_40.csv   output_val_epoch_15.csv    output_val_epoch_81.csv\r\n",
      "output_train_epoch_41.csv   output_val_epoch_16.csv    output_val_epoch_82.csv\r\n",
      "output_train_epoch_42.csv   output_val_epoch_17.csv    output_val_epoch_83.csv\r\n",
      "output_train_epoch_43.csv   output_val_epoch_18.csv    output_val_epoch_84.csv\r\n",
      "output_train_epoch_44.csv   output_val_epoch_19.csv    output_val_epoch_85.csv\r\n",
      "output_train_epoch_45.csv   output_val_epoch_1.csv     output_val_epoch_86.csv\r\n",
      "output_train_epoch_46.csv   output_val_epoch_20.csv    output_val_epoch_87.csv\r\n",
      "output_train_epoch_47.csv   output_val_epoch_21.csv    output_val_epoch_88.csv\r\n",
      "output_train_epoch_48.csv   output_val_epoch_22.csv    output_val_epoch_89.csv\r\n",
      "output_train_epoch_49.csv   output_val_epoch_23.csv    output_val_epoch_8.csv\r\n",
      "output_train_epoch_4.csv    output_val_epoch_24.csv    output_val_epoch_90.csv\r\n",
      "output_train_epoch_50.csv   output_val_epoch_25.csv    output_val_epoch_91.csv\r\n",
      "output_train_epoch_51.csv   output_val_epoch_26.csv    output_val_epoch_92.csv\r\n",
      "output_train_epoch_52.csv   output_val_epoch_27.csv    output_val_epoch_93.csv\r\n",
      "output_train_epoch_53.csv   output_val_epoch_28.csv    output_val_epoch_94.csv\r\n",
      "output_train_epoch_54.csv   output_val_epoch_29.csv    output_val_epoch_95.csv\r\n",
      "output_train_epoch_55.csv   output_val_epoch_2.csv     output_val_epoch_96.csv\r\n",
      "output_train_epoch_56.csv   output_val_epoch_30.csv    output_val_epoch_97.csv\r\n",
      "output_train_epoch_57.csv   output_val_epoch_31.csv    output_val_epoch_98.csv\r\n",
      "output_train_epoch_58.csv   output_val_epoch_32.csv    output_val_epoch_99.csv\r\n",
      "output_train_epoch_59.csv   output_val_epoch_33.csv    output_val_epoch_9.csv\r\n",
      "output_train_epoch_5.csv    output_val_epoch_34.csv    part1and2_data\r\n",
      "output_train_epoch_60.csv   output_val_epoch_35.csv    train.csv\r\n",
      "output_train_epoch_61.csv   output_val_epoch_36.csv    val.csv\r\n",
      "output_train_epoch_62.csv   output_val_epoch_37.csv\r\n",
      "output_train_epoch_63.csv   output_val_epoch_38.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/thiennguyen/research/pseudogroups/CUB/autolog_splitpgl/erm_upweight-1_epochs101_lr0.001_wd0.0001/part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import run_epoch\n",
    "from loss import LossComputer\n",
    "import numpy as np \n",
    "\n",
    "part2_log_dir = \"/home/thiennguyen/research/pseudogroups/CUB/autolog_splitpgl/erm_upweight-1_epochs101_lr0.001_wd0.0001/part2_eval\"\n",
    "if not os.path.exists(part2_log_dir):\n",
    "    os.makedirs(part2_log_dir)\n",
    "part2_logger = Logger(os.path.join(part2_log_dir, \"log.txt\"), 'w')\n",
    "part2_logger.flush()\n",
    "\n",
    "part1_log_dir = \"/home/thiennguyen/research/pseudogroups/CUB/autolog_splitpgl/erm_upweight-1_epochs101_lr0.001_wd0.0001/part1/\"\n",
    "model_path = f\"{part1_log_dir}/90_model.pth\"\n",
    "# first load the previous model\n",
    "modeleval = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading './cub/data/waterbird_complete95_forest2water2/metadata.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 38/38 [00:03<00:00, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /home/thiennguyen/research/pseudogroups/CUB/autolog_splitpgl/erm_upweight-1_epochs101_lr0.001_wd0.0001/part2_eval/output_part2_eval_epoch_0.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.104  \n",
      "Average sample loss: 0.105  \n",
      "Average acc: 0.970  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1756]:\tloss = 0.017  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 91]:\tloss = 1.219  exp loss = 1.541  adjusted loss = 1.541  adv prob = 0.250000   acc = 0.626\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:\tloss = 1.696  exp loss = 1.125  adjusted loss = 1.125  adv prob = 0.250000   acc = 0.720\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 526]:\tloss = 0.127  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize logger and loader for part2\n",
    "mode='w'\n",
    "train_data, val_data, test_data = prepare_data(args, train=True)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "loader_kwargs = {\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"num_workers\": 4,\n",
    "        \"pin_memory\": True}\n",
    "part2_data = torch.load(os.path.join(part1_log_dir,\"part1and2_data\"))[\"part2\"]\n",
    "part2eval_csv_logger = CSVBatchLogger(os.path.join(part2_log_dir, f\"part2_eval.csv\"),\n",
    "                                 test_data.n_groups,\n",
    "                                 mode=mode)\n",
    "part2_loader = dro_dataset.get_loader(part2_data,\n",
    "                                      train=False,\n",
    "                                      reweight_groups=None,\n",
    "                                      **loader_kwargs)\n",
    "adjustments = np.array([float(c) for c in args.generalization_adjustment.split(\",\")]* 4)\n",
    "part2_loss_computer = LossComputer(\n",
    "            criterion,\n",
    "            loss_type=args.loss_type,\n",
    "            dataset=train_data,\n",
    "            alpha=args.alpha,\n",
    "            gamma=args.gamma,\n",
    "            adj=adjustments,\n",
    "            step_size=args.robust_step_size,\n",
    "            normalize_loss=args.use_normalized_loss,\n",
    "            btl=args.btl,\n",
    "            min_var_weight=args.minimum_variational_weight,\n",
    "            joint_dro_alpha=args.joint_dro_alpha,\n",
    "        )\n",
    "\n",
    "# then run an epoch on part2 and during that run, generate a csv containing the status of each example \n",
    "run_epoch(\n",
    "    epoch=0,\n",
    "    model=modeleval,\n",
    "    optimizer=None,\n",
    "    loader=part2_loader,\n",
    "    loss_computer=part2_loss_computer,\n",
    "    logger=part2_logger,\n",
    "    csv_logger=part2eval_csv_logger,\n",
    "    args=args,\n",
    "    is_training=False,\n",
    "    show_progress=True,\n",
    "    log_every=50,\n",
    "    scheduler=None,\n",
    "    csv_name=\"pseudogroup_eval\",\n",
    "    wandb_group=\"part2_eval\",\n",
    "    wandb=wandb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 542682... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_idx</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>part2_eval/avg_acc</td><td>▁</td></tr><tr><td>part2_eval/avg_acc_group:0</td><td>▁</td></tr><tr><td>part2_eval/avg_acc_group:1</td><td>▁</td></tr><tr><td>part2_eval/avg_acc_group:2</td><td>▁</td></tr><tr><td>part2_eval/avg_acc_group:3</td><td>▁</td></tr><tr><td>part2_eval/avg_actual_loss</td><td>▁</td></tr><tr><td>part2_eval/avg_loss_group:0</td><td>▁</td></tr><tr><td>part2_eval/avg_loss_group:1</td><td>▁</td></tr><tr><td>part2_eval/avg_loss_group:2</td><td>▁</td></tr><tr><td>part2_eval/avg_loss_group:3</td><td>▁</td></tr><tr><td>part2_eval/avg_per_sample_loss</td><td>▁</td></tr><tr><td>part2_eval/exp_avg_loss_group:0</td><td>▁</td></tr><tr><td>part2_eval/exp_avg_loss_group:1</td><td>▁</td></tr><tr><td>part2_eval/exp_avg_loss_group:2</td><td>▁</td></tr><tr><td>part2_eval/exp_avg_loss_group:3</td><td>▁</td></tr><tr><td>part2_eval/model_norm_sq</td><td>▁</td></tr><tr><td>part2_eval/processed_data_count_group:0</td><td>▁</td></tr><tr><td>part2_eval/processed_data_count_group:1</td><td>▁</td></tr><tr><td>part2_eval/processed_data_count_group:2</td><td>▁</td></tr><tr><td>part2_eval/processed_data_count_group:3</td><td>▁</td></tr><tr><td>part2_eval/reg_loss</td><td>▁</td></tr><tr><td>part2_eval/update_batch_count_group:0</td><td>▁</td></tr><tr><td>part2_eval/update_batch_count_group:1</td><td>▁</td></tr><tr><td>part2_eval/update_batch_count_group:2</td><td>▁</td></tr><tr><td>part2_eval/update_batch_count_group:3</td><td>▁</td></tr><tr><td>part2_eval/update_data_count_group:0</td><td>▁</td></tr><tr><td>part2_eval/update_data_count_group:1</td><td>▁</td></tr><tr><td>part2_eval/update_data_count_group:2</td><td>▁</td></tr><tr><td>part2_eval/update_data_count_group:3</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_idx</td><td>37</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>part2_eval/avg_acc</td><td>0.97039</td></tr><tr><td>part2_eval/avg_acc_group:0</td><td>0.99544</td></tr><tr><td>part2_eval/avg_acc_group:1</td><td>0.62637</td></tr><tr><td>part2_eval/avg_acc_group:2</td><td>0.72</td></tr><tr><td>part2_eval/avg_acc_group:3</td><td>0.95817</td></tr><tr><td>part2_eval/avg_actual_loss</td><td>0.10518</td></tr><tr><td>part2_eval/avg_loss_group:0</td><td>0.01661</td></tr><tr><td>part2_eval/avg_loss_group:1</td><td>1.21941</td></tr><tr><td>part2_eval/avg_loss_group:2</td><td>1.69602</td></tr><tr><td>part2_eval/avg_loss_group:3</td><td>0.12746</td></tr><tr><td>part2_eval/avg_per_sample_loss</td><td>0.10408</td></tr><tr><td>part2_eval/exp_avg_loss_group:0</td><td>0.01829</td></tr><tr><td>part2_eval/exp_avg_loss_group:1</td><td>1.5408</td></tr><tr><td>part2_eval/exp_avg_loss_group:2</td><td>1.12549</td></tr><tr><td>part2_eval/exp_avg_loss_group:3</td><td>0.0915</td></tr><tr><td>part2_eval/model_norm_sq</td><td>8375.46191</td></tr><tr><td>part2_eval/processed_data_count_group:0</td><td>1756.0</td></tr><tr><td>part2_eval/processed_data_count_group:1</td><td>91.0</td></tr><tr><td>part2_eval/processed_data_count_group:2</td><td>25.0</td></tr><tr><td>part2_eval/processed_data_count_group:3</td><td>526.0</td></tr><tr><td>part2_eval/reg_loss</td><td>0.41877</td></tr><tr><td>part2_eval/update_batch_count_group:0</td><td>38.0</td></tr><tr><td>part2_eval/update_batch_count_group:1</td><td>35.0</td></tr><tr><td>part2_eval/update_batch_count_group:2</td><td>18.0</td></tr><tr><td>part2_eval/update_batch_count_group:3</td><td>38.0</td></tr><tr><td>part2_eval/update_data_count_group:0</td><td>1756.0</td></tr><tr><td>part2_eval/update_data_count_group:1</td><td>91.0</td></tr><tr><td>part2_eval/update_data_count_group:2</td><td>25.0</td></tr><tr><td>part2_eval/update_data_count_group:3</td><td>526.0</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">usual-shape-73</strong>: <a href=\"https://wandb.ai/thien/spurious_CUB/runs/lmq8fcm5\" target=\"_blank\">https://wandb.ai/thien/spurious_CUB/runs/lmq8fcm5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211009_003251-lmq8fcm5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then generate pseudogroup labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data.folds import ConcatDataset\n",
    "\n",
    "# want to create a sampler so that misclassified examples of each label is sampled \"more frequently\"\n",
    "# the pseudogroup labels are located in part2_log_dir/output_eval_epoch_0.csv under \n",
    "#     y_pred_pseudogroup_eval_epoch_0_val and y_true_pseudogroup_eval_epoch_0_val columns...\n",
    "#     the group is (y_true, y_pred==y_true)\n",
    "part2_df = pd.read_csv(os.path.join(part2_log_dir,'output_part2_eval_epoch_0.csv'))\n",
    "misclassified = part2_df['y_pred_pseudogroup_eval_epoch_0_val'] != part2_df['y_true_pseudogroup_eval_epoch_0_val']\n",
    "aug_indices = part2_df['indices_pseudogroup_eval_epoch_0_val'][misclassified]\n",
    "upweight_factor = len(part2_df)//len(aug_indices)\n",
    "combined_indices = list(aug_indices) * upweight_factor + list(part2_df['indices_pseudogroup_eval_epoch_0_val'])\n",
    "upsampled_part2 = torch.utils.data.Subset(train_data.dataset.dataset, combined_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1805.,   42.,  522.,   29.])\n",
      "tensor([ 1.3285, 57.0952,  4.5939, 82.6897])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data.folds import ConcatDataset\n",
    "\n",
    "n_classes = part2_data.n_classes\n",
    "part2_df = pd.read_csv(os.path.join(part2_log_dir, 'output_part2_eval_epoch_0.csv'))\n",
    "n_groups = n_classes*2\n",
    "true_y = part2_df['y_true_pseudogroup_eval_epoch_0_val']\n",
    "pred_y = part2_df['y_pred_pseudogroup_eval_epoch_0_val']\n",
    "misclassified = true_y != pred_y\n",
    "group_array = misclassified + true_y*2  # times 2 to make group (true_y, status)\n",
    "# print(group_array)\n",
    "group_counts = (torch.arange(n_groups).unsqueeze(1) == torch.tensor(group_array)).sum(1).float()\n",
    "print(group_counts)\n",
    "group_weights = len(part2_data)/ group_counts\n",
    "print(group_weights)\n",
    "weights = group_weights[group_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1365 [0]\n",
      "1 11701 [1]\n",
      "2 1249 [2]\n",
      "3 9201 [3]\n",
      "4 6565 [4]\n",
      "5 4241 [5]\n",
      "6 445 [6]\n",
      "7 8111 [7]\n",
      "8 7527 [8]\n",
      "9 4984 [9]\n",
      "10 627 [10]\n",
      "11 10578 [11]\n",
      "12 9282 [12]\n",
      "13 1922 [13]\n",
      "14 6293 [14]\n",
      "15 3901 [15]\n",
      "16 644 [16]\n",
      "17 9843 [17]\n",
      "18 7644 [18]\n",
      "19 3404 [19]\n",
      "20 872 [20]\n",
      "21 4839 [21]\n",
      "22 2002 [22]\n",
      "23 8960 [23]\n",
      "24 4007 [24]\n",
      "25 11075 [25]\n",
      "26 2470 [26]\n",
      "27 4608 [27]\n",
      "28 4347 [28]\n",
      "29 5278 [29]\n",
      "30 1600 [30]\n",
      "31 8336 [31]\n",
      "32 654 [32]\n",
      "33 1820 [33]\n",
      "34 11138 [34]\n",
      "35 11217 [35]\n",
      "36 1581 [36]\n",
      "37 7287 [37]\n",
      "38 599 [38]\n",
      "39 9069 [39]\n",
      "40 7978 [40]\n",
      "41 600 [41]\n",
      "42 8963 [42]\n",
      "43 8192 [43]\n",
      "44 7163 [44]\n",
      "45 2242 [45]\n",
      "46 1683 [46]\n",
      "47 7413 [47]\n",
      "48 4448 [48]\n",
      "49 9128 [49]\n",
      "50 220 [50]\n",
      "51 10235 [51]\n",
      "52 10279 [52]\n",
      "53 5195 [53]\n",
      "54 2105 [54]\n",
      "55 5641 [55]\n",
      "56 6266 [56]\n",
      "57 4342 [57]\n",
      "58 5618 [58]\n",
      "59 4404 [59]\n",
      "60 1301 [60]\n",
      "61 994 [61]\n",
      "62 9935 [62]\n",
      "63 363 [63]\n",
      "64 7799 [64]\n",
      "65 2319 [65]\n",
      "66 4490 [66]\n",
      "67 5415 [67]\n",
      "68 8229 [68]\n",
      "69 1367 [69]\n",
      "70 9294 [70]\n",
      "71 5075 [71]\n",
      "72 8339 [72]\n",
      "73 2464 [73]\n",
      "74 8082 [74]\n",
      "75 9268 [75]\n",
      "76 5321 [76]\n",
      "77 9312 [77]\n",
      "78 2252 [78]\n",
      "79 9424 [79]\n",
      "80 335 [80]\n",
      "81 2186 [81]\n",
      "82 8444 [82]\n",
      "83 2240 [83]\n",
      "84 2448 [84]\n",
      "85 5286 [85]\n",
      "86 2384 [86]\n",
      "87 750 [87]\n",
      "88 4262 [88]\n",
      "89 7321 [89]\n",
      "90 5339 [90]\n",
      "91 7789 [91]\n",
      "92 587 [92]\n",
      "93 4238 [93]\n",
      "94 10940 [94]\n",
      "95 10619 [95]\n",
      "96 9079 [96]\n",
      "97 8832 [97]\n",
      "98 5416 [98]\n",
      "99 4852 [99]\n",
      "100 11021 [100]\n",
      "101 8860 [101]\n",
      "102 35 [102]\n",
      "103 378 [103]\n",
      "104 510 [104]\n",
      "105 9350 [105]\n",
      "106 4265 [106]\n",
      "107 11072 [107]\n",
      "108 11209 [108]\n",
      "109 5629 [109]\n",
      "110 10764 [110]\n",
      "111 666 [111]\n",
      "112 5399 [112]\n",
      "113 1670 [113]\n",
      "114 11613 [114]\n",
      "115 11070 [115]\n",
      "116 1218 [116]\n",
      "117 121 [117]\n",
      "118 8166 [118]\n",
      "119 580 [119]\n",
      "120 7266 [120]\n",
      "121 1514 [121]\n",
      "122 9671 [122]\n",
      "123 11236 [123]\n",
      "124 8973 [124]\n",
      "125 616 [125]\n",
      "126 705 [126]\n",
      "127 6476 [127]\n",
      "128 5291 [128]\n",
      "129 1917 [129]\n",
      "130 3179 [130]\n",
      "131 6585 [131]\n",
      "132 321 [132]\n",
      "133 1428 [133]\n",
      "134 1743 [134]\n",
      "135 5887 [135]\n",
      "136 9550 [136]\n",
      "137 8103 [137]\n",
      "138 7081 [138]\n",
      "139 3914 [139]\n",
      "140 5521 [140]\n",
      "141 2538 [141]\n",
      "142 1102 [142]\n",
      "143 869 [143]\n",
      "144 5288 [144]\n",
      "145 9516 [145]\n",
      "146 10784 [146]\n",
      "147 8636 [147]\n",
      "148 827 [148]\n",
      "149 298 [149]\n",
      "150 9839 [150]\n",
      "151 4068 [151]\n",
      "152 8596 [152]\n",
      "153 1931 [153]\n",
      "154 3574 [154]\n",
      "155 1231 [155]\n",
      "156 1763 [156]\n",
      "157 11271 [157]\n",
      "158 1518 [158]\n",
      "159 9016 [159]\n",
      "160 10829 [160]\n",
      "161 3496 [161]\n",
      "162 11663 [162]\n",
      "163 8235 [163]\n",
      "164 10692 [164]\n",
      "165 5022 [165]\n",
      "166 9436 [166]\n",
      "167 4301 [167]\n",
      "168 9339 [168]\n",
      "169 3255 [169]\n",
      "170 6315 [170]\n",
      "171 10517 [171]\n",
      "172 5326 [172]\n",
      "173 11298 [173]\n",
      "174 4231 [174]\n",
      "175 3305 [175]\n",
      "176 9623 [176]\n",
      "177 964 [177]\n",
      "178 7459 [178]\n",
      "179 8428 [179]\n",
      "180 7560 [180]\n",
      "181 3069 [181]\n",
      "182 6393 [182]\n",
      "183 3589 [183]\n",
      "184 6087 [184]\n",
      "185 1252 [185]\n",
      "186 2385 [186]\n",
      "187 4936 [187]\n",
      "188 10549 [188]\n",
      "189 6021 [189]\n",
      "190 1888 [190]\n",
      "191 10775 [191]\n",
      "192 1539 [192]\n",
      "193 3041 [193]\n",
      "194 10179 [194]\n",
      "195 8003 [195]\n",
      "196 2478 [196]\n",
      "197 3116 [197]\n",
      "198 8727 [198]\n",
      "199 8426 [199]\n",
      "200 4800 [200]\n",
      "201 3954 [201]\n",
      "202 9062 [202]\n",
      "203 6460 [203]\n",
      "204 4561 [204]\n",
      "205 2855 [205]\n",
      "206 2641 [206]\n",
      "207 6949 [207]\n",
      "208 9607 [208]\n",
      "209 10999 [209]\n",
      "210 979 [210]\n",
      "211 5443 [211]\n",
      "212 534 [212]\n",
      "213 10274 [213]\n",
      "214 6514 [214]\n",
      "215 5270 [215]\n",
      "216 8969 [216]\n",
      "217 10877 [217]\n",
      "218 4717 [218]\n",
      "219 11515 [219]\n",
      "220 1021 [220]\n",
      "221 2175 [221]\n",
      "222 661 [222]\n",
      "223 2078 [223]\n",
      "224 9593 [224]\n",
      "225 4854 [225]\n",
      "226 934 [226]\n",
      "227 7845 [227]\n",
      "228 9595 [228]\n",
      "229 2792 [229]\n",
      "230 8755 [230]\n",
      "231 3636 [231]\n",
      "232 4475 [232]\n",
      "233 1087 [233]\n",
      "234 9390 [234]\n",
      "235 3801 [235]\n",
      "236 9227 [236]\n",
      "237 10993 [237]\n",
      "238 8631 [238]\n",
      "239 3019 [239]\n",
      "240 6606 [240]\n",
      "241 2077 [241]\n",
      "242 2511 [242]\n",
      "243 10850 [243]\n",
      "244 11450 [244]\n",
      "245 8571 [245]\n",
      "246 9252 [246]\n",
      "247 10594 [247]\n",
      "248 2700 [248]\n",
      "249 4548 [249]\n",
      "250 3199 [250]\n",
      "251 1310 [251]\n",
      "252 7367 [252]\n",
      "253 10662 [253]\n",
      "254 2184 [254]\n",
      "255 6509 [255]\n",
      "256 227 [256]\n",
      "257 6348 [257]\n",
      "258 4716 [258]\n",
      "259 3674 [259]\n",
      "260 221 [260]\n",
      "261 6324 [261]\n",
      "262 8061 [262]\n",
      "263 3381 [263]\n",
      "264 1548 [264]\n",
      "265 2316 [265]\n",
      "266 561 [266]\n",
      "267 158 [267]\n",
      "268 3719 [268]\n",
      "269 10701 [269]\n",
      "270 8876 [270]\n",
      "271 2561 [271]\n",
      "272 2331 [272]\n",
      "273 7830 [273]\n",
      "274 5959 [274]\n",
      "275 4519 [275]\n",
      "276 3739 [276]\n",
      "277 3247 [277]\n",
      "278 8182 [278]\n",
      "279 10579 [279]\n",
      "280 4866 [280]\n",
      "281 3148 [281]\n",
      "282 10953 [282]\n",
      "283 10133 [283]\n",
      "284 1668 [284]\n",
      "285 953 [285]\n",
      "286 2998 [286]\n",
      "287 8764 [287]\n",
      "288 11642 [288]\n",
      "289 10107 [289]\n",
      "290 4937 [290]\n",
      "291 7869 [291]\n",
      "292 5407 [292]\n",
      "293 9747 [293]\n",
      "294 10270 [294]\n",
      "295 10403 [295]\n",
      "296 5039 [296]\n",
      "297 11384 [297]\n",
      "298 10263 [298]\n",
      "299 3501 [299]\n",
      "300 5006 [300]\n",
      "301 6934 [301]\n",
      "302 5098 [302]\n",
      "303 5152 [303]\n",
      "304 6148 [304]\n",
      "305 11745 [305]\n",
      "306 4414 [306]\n",
      "307 8490 [307]\n",
      "308 2767 [308]\n",
      "309 8758 [309]\n",
      "310 11489 [310]\n",
      "311 9092 [311]\n",
      "312 5354 [312]\n",
      "313 1333 [313]\n",
      "314 9210 [314]\n",
      "315 7953 [315]\n",
      "316 11332 [316]\n",
      "317 3144 [317]\n",
      "318 5589 [318]\n",
      "319 7037 [319]\n",
      "320 3043 [320]\n",
      "321 10251 [321]\n",
      "322 7193 [322]\n",
      "323 10963 [323]\n",
      "324 4870 [324]\n",
      "325 4547 [325]\n",
      "326 10629 [326]\n",
      "327 1515 [327]\n",
      "328 4808 [328]\n",
      "329 10978 [329]\n",
      "330 9445 [330]\n",
      "331 10730 [331]\n",
      "332 9202 [332]\n",
      "333 6264 [333]\n",
      "334 1474 [334]\n",
      "335 2454 [335]\n",
      "336 2000 [336]\n",
      "337 1364 [337]\n",
      "338 7073 [338]\n",
      "339 5873 [339]\n",
      "340 3118 [340]\n",
      "341 10801 [341]\n",
      "342 10968 [342]\n",
      "343 6446 [343]\n",
      "344 519 [344]\n",
      "345 5792 [345]\n",
      "346 8401 [346]\n",
      "347 8160 [347]\n",
      "348 4494 [348]\n",
      "349 2037 [349]\n",
      "350 3677 [350]\n",
      "351 2949 [351]\n",
      "352 3775 [352]\n",
      "353 1459 [353]\n",
      "354 983 [354]\n",
      "355 3039 [355]\n",
      "356 7333 [356]\n",
      "357 266 [357]\n",
      "358 5879 [358]\n",
      "359 7428 [359]\n",
      "360 11302 [360]\n",
      "361 7540 [361]\n",
      "362 95 [362]\n",
      "363 3276 [363]\n",
      "364 9868 [364]\n",
      "365 2665 [365]\n",
      "366 3280 [366]\n",
      "367 10112 [367]\n",
      "368 9477 [368]\n",
      "369 10804 [369]\n",
      "370 6699 [370]\n",
      "371 9246 [371]\n",
      "372 5193 [372]\n",
      "373 10353 [373]\n",
      "374 7277 [374]\n",
      "375 6463 [375]\n",
      "376 9114 [376]\n",
      "377 3538 [377]\n",
      "378 8827 [378]\n",
      "379 5267 [379]\n",
      "380 4963 [380]\n",
      "381 10647 [381]\n",
      "382 3729 [382]\n",
      "383 1326 [383]\n",
      "384 2575 [384]\n",
      "385 3532 [385]\n",
      "386 428 [386]\n",
      "387 2667 [387]\n",
      "388 3774 [388]\n",
      "389 2198 [389]\n",
      "390 5769 [390]\n",
      "391 8634 [391]\n",
      "392 8191 [392]\n",
      "393 10415 [393]\n",
      "394 6249 [394]\n",
      "395 2457 [395]\n",
      "396 3892 [396]\n",
      "397 791 [397]\n",
      "398 11588 [398]\n",
      "399 10375 [399]\n",
      "400 387 [400]\n",
      "401 3138 [401]\n",
      "402 2728 [402]\n",
      "403 7400 [403]\n",
      "404 2563 [404]\n",
      "405 10268 [405]\n",
      "406 11014 [406]\n",
      "407 2150 [407]\n",
      "408 714 [408]\n",
      "409 3810 [409]\n",
      "410 5838 [410]\n",
      "411 9505 [411]\n",
      "412 7514 [412]\n",
      "413 9873 [413]\n",
      "414 11467 [414]\n",
      "415 7076 [415]\n",
      "416 6862 [416]\n",
      "417 9809 [417]\n",
      "418 2165 [418]\n",
      "419 5374 [419]\n",
      "420 5715 [420]\n",
      "421 7022 [421]\n",
      "422 11068 [422]\n",
      "423 8458 [423]\n",
      "424 3888 [424]\n",
      "425 667 [425]\n",
      "426 8145 [426]\n",
      "427 5818 [427]\n",
      "428 2239 [428]\n",
      "429 7028 [429]\n",
      "430 3904 [430]\n",
      "431 1838 [431]\n",
      "432 1689 [432]\n",
      "433 4529 [433]\n",
      "434 670 [434]\n",
      "435 8730 [435]\n",
      "436 8455 [436]\n",
      "437 950 [437]\n",
      "438 5449 [438]\n",
      "439 10611 [439]\n",
      "440 224 [440]\n",
      "441 10269 [441]\n",
      "442 7185 [442]\n",
      "443 3384 [443]\n",
      "444 2323 [444]\n",
      "445 9005 [445]\n",
      "446 6084 [446]\n",
      "447 7787 [447]\n",
      "448 6215 [448]\n",
      "449 3442 [449]\n",
      "450 8228 [450]\n",
      "451 2525 [451]\n",
      "452 5492 [452]\n",
      "453 4893 [453]\n",
      "454 4253 [454]\n",
      "455 7126 [455]\n",
      "456 4533 [456]\n",
      "457 2723 [457]\n",
      "458 9217 [458]\n",
      "459 2166 [459]\n",
      "460 3037 [460]\n",
      "461 193 [461]\n",
      "462 5442 [462]\n",
      "463 3627 [463]\n",
      "464 3121 [464]\n",
      "465 7150 [465]\n",
      "466 10958 [466]\n",
      "467 9431 [467]\n",
      "468 4048 [468]\n",
      "469 10305 [469]\n",
      "470 8141 [470]\n",
      "471 8501 [471]\n",
      "472 6487 [472]\n",
      "473 425 [473]\n",
      "474 8611 [474]\n",
      "475 6740 [475]\n",
      "476 9645 [476]\n",
      "477 3001 [477]\n",
      "478 3348 [478]\n",
      "479 7773 [479]\n",
      "480 10800 [480]\n",
      "481 2542 [481]\n",
      "482 256 [482]\n",
      "483 9575 [483]\n",
      "484 10960 [484]\n",
      "485 103 [485]\n",
      "486 7895 [486]\n",
      "487 7454 [487]\n",
      "488 10349 [488]\n",
      "489 5657 [489]\n",
      "490 9021 [490]\n",
      "491 1112 [491]\n",
      "492 8238 [492]\n",
      "493 6289 [493]\n",
      "494 389 [494]\n",
      "495 7769 [495]\n",
      "496 8471 [496]\n",
      "497 1553 [497]\n",
      "498 6808 [498]\n",
      "499 6398 [499]\n",
      "500 8710 [500]\n",
      "501 1258 [501]\n",
      "502 6505 [502]\n",
      "503 9681 [503]\n",
      "504 10956 [504]\n",
      "505 8733 [505]\n",
      "506 2883 [506]\n",
      "507 9793 [507]\n",
      "508 2653 [508]\n",
      "509 9386 [509]\n",
      "510 5994 [510]\n",
      "511 1460 [511]\n",
      "512 9706 [512]\n",
      "513 9830 [513]\n",
      "514 755 [514]\n",
      "515 4406 [515]\n",
      "516 777 [516]\n",
      "517 1863 [517]\n",
      "518 9674 [518]\n",
      "519 7648 [519]\n",
      "520 9773 [520]\n",
      "521 9900 [521]\n",
      "522 2619 [522]\n",
      "523 4950 [523]\n",
      "524 1057 [524]\n",
      "525 3207 [525]\n",
      "526 8535 [526]\n",
      "527 6 [527]\n",
      "528 8558 [528]\n",
      "529 11368 [529]\n",
      "530 4699 [530]\n",
      "531 2387 [531]\n",
      "532 7467 [532]\n",
      "533 8294 [533]\n",
      "534 874 [534]\n",
      "535 11060 [535]\n",
      "536 10691 [536]\n",
      "537 8287 [537]\n",
      "538 11505 [538]\n",
      "539 2260 [539]\n",
      "540 468 [540]\n",
      "541 8421 [541]\n",
      "542 2135 [542]\n",
      "543 5874 [543]\n",
      "544 9978 [544]\n",
      "545 5413 [545]\n",
      "546 5438 [546]\n",
      "547 5241 [547]\n",
      "548 1766 [548]\n",
      "549 11676 [549]\n",
      "550 1640 [550]\n",
      "551 3769 [551]\n",
      "552 3811 [552]\n",
      "553 11184 [553]\n",
      "554 5772 [554]\n",
      "555 8588 [555]\n",
      "556 5130 [556]\n",
      "557 1566 [557]\n",
      "558 11234 [558]\n",
      "559 9514 [559]\n",
      "560 5582 [560]\n",
      "561 4017 [561]\n",
      "562 361 [562]\n",
      "563 8052 [563]\n",
      "564 6434 [564]\n",
      "565 3531 [565]\n",
      "566 7728 [566]\n",
      "567 2270 [567]\n",
      "568 11391 [568]\n",
      "569 856 [569]\n",
      "570 3285 [570]\n",
      "571 8322 [571]\n",
      "572 861 [572]\n",
      "573 3114 [573]\n",
      "574 5499 [574]\n",
      "575 3609 [575]\n",
      "576 2929 [576]\n",
      "577 5002 [577]\n",
      "578 9058 [578]\n",
      "579 3649 [579]\n",
      "580 5789 [580]\n",
      "581 9407 [581]\n",
      "582 7306 [582]\n",
      "583 6848 [583]\n",
      "584 8766 [584]\n",
      "585 8680 [585]\n",
      "586 9408 [586]\n",
      "587 5511 [587]\n",
      "588 1419 [588]\n",
      "589 8390 [589]\n",
      "590 9017 [590]\n",
      "591 2953 [591]\n",
      "592 7957 [592]\n",
      "593 2624 [593]\n",
      "594 4067 [594]\n",
      "595 945 [595]\n",
      "596 10214 [596]\n",
      "597 8660 [597]\n",
      "598 2045 [598]\n",
      "599 6535 [599]\n",
      "600 1587 [600]\n",
      "601 6944 [601]\n",
      "602 3064 [602]\n",
      "603 9119 [603]\n",
      "604 11092 [604]\n",
      "605 263 [605]\n",
      "606 1487 [606]\n",
      "607 2332 [607]\n",
      "608 11182 [608]\n",
      "609 7153 [609]\n",
      "610 11721 [610]\n",
      "611 8986 [611]\n",
      "612 10538 [612]\n",
      "613 3736 [613]\n",
      "614 10967 [614]\n",
      "615 3978 [615]\n",
      "616 5209 [616]\n",
      "617 5969 [617]\n",
      "618 1563 [618]\n",
      "619 11381 [619]\n",
      "620 647 [620]\n",
      "621 4455 [621]\n",
      "622 4349 [622]\n",
      "623 7484 [623]\n",
      "624 10423 [624]\n",
      "625 2011 [625]\n",
      "626 8723 [626]\n",
      "627 8137 [627]\n",
      "628 2662 [628]\n",
      "629 1597 [629]\n",
      "630 9542 [630]\n",
      "631 4157 [631]\n",
      "632 5580 [632]\n",
      "633 5757 [633]\n",
      "634 11400 [634]\n",
      "635 4618 [635]\n",
      "636 3608 [636]\n",
      "637 71 [637]\n",
      "638 5259 [638]\n",
      "639 6968 [639]\n",
      "640 5825 [640]\n",
      "641 2374 [641]\n",
      "642 3760 [642]\n",
      "643 7991 [643]\n",
      "644 4813 [644]\n",
      "645 10159 [645]\n",
      "646 4154 [646]\n",
      "647 443 [647]\n",
      "648 11126 [648]\n",
      "649 876 [649]\n",
      "650 3370 [650]\n",
      "651 11507 [651]\n",
      "652 3573 [652]\n",
      "653 2902 [653]\n",
      "654 9530 [654]\n",
      "655 7092 [655]\n",
      "656 4656 [656]\n",
      "657 7273 [657]\n",
      "658 8547 [658]\n",
      "659 7293 [659]\n",
      "660 293 [660]\n",
      "661 3391 [661]\n",
      "662 1662 [662]\n",
      "663 5628 [663]\n",
      "664 4776 [664]\n",
      "665 237 [665]\n",
      "666 2840 [666]\n",
      "667 5979 [667]\n",
      "668 3439 [668]\n",
      "669 8798 [669]\n",
      "670 1308 [670]\n",
      "671 1730 [671]\n",
      "672 503 [672]\n",
      "673 3122 [673]\n",
      "674 7839 [674]\n",
      "675 11578 [675]\n",
      "676 4664 [676]\n",
      "677 6819 [677]\n",
      "678 6034 [678]\n",
      "679 1022 [679]\n",
      "680 8836 [680]\n",
      "681 5746 [681]\n",
      "682 282 [682]\n",
      "683 3969 [683]\n",
      "684 981 [684]\n",
      "685 2219 [685]\n",
      "686 2262 [686]\n",
      "687 3960 [687]\n",
      "688 2181 [688]\n",
      "689 5594 [689]\n",
      "690 1397 [690]\n",
      "691 1851 [691]\n",
      "692 11579 [692]\n",
      "693 10606 [693]\n",
      "694 774 [694]\n",
      "695 2754 [695]\n",
      "696 3694 [696]\n",
      "697 6308 [697]\n",
      "698 440 [698]\n",
      "699 8120 [699]\n",
      "700 6559 [700]\n",
      "701 8308 [701]\n",
      "702 1809 [702]\n",
      "703 8846 [703]\n",
      "704 2404 [704]\n",
      "705 11432 [705]\n",
      "706 4518 [706]\n",
      "707 408 [707]\n",
      "708 1146 [708]\n",
      "709 5322 [709]\n",
      "710 10848 [710]\n",
      "711 724 [711]\n",
      "712 7294 [712]\n",
      "713 3696 [713]\n",
      "714 7633 [714]\n",
      "715 10182 [715]\n",
      "716 22 [716]\n",
      "717 10723 [717]\n",
      "718 465 [718]\n",
      "719 1 [719]\n",
      "720 5146 [720]\n",
      "721 11022 [721]\n",
      "722 4330 [722]\n",
      "723 2557 [723]\n",
      "724 6886 [724]\n",
      "725 2864 [725]\n",
      "726 11146 [726]\n",
      "727 1207 [727]\n",
      "728 4660 [728]\n",
      "729 2522 [729]\n",
      "730 5424 [730]\n",
      "731 6936 [731]\n",
      "732 6057 [732]\n",
      "733 10196 [733]\n",
      "734 3780 [734]\n",
      "735 740 [735]\n",
      "736 4320 [736]\n",
      "737 2247 [737]\n",
      "738 10807 [738]\n",
      "739 3401 [739]\n",
      "740 3571 [740]\n",
      "741 275 [741]\n",
      "742 9703 [742]\n",
      "743 4278 [743]\n",
      "744 6125 [744]\n",
      "745 2860 [745]\n",
      "746 7911 [746]\n",
      "747 3794 [747]\n",
      "748 2082 [748]\n",
      "749 3423 [749]\n",
      "750 3522 [750]\n",
      "751 11353 [751]\n",
      "752 11155 [752]\n",
      "753 2124 [753]\n",
      "754 2055 [754]\n",
      "755 2395 [755]\n",
      "756 234 [756]\n",
      "757 8703 [757]\n",
      "758 8302 [758]\n",
      "759 1269 [759]\n",
      "760 11073 [760]\n",
      "761 1368 [761]\n",
      "762 4736 [762]\n",
      "763 4275 [763]\n",
      "764 538 [764]\n",
      "765 2397 [765]\n",
      "766 9287 [766]\n",
      "767 11152 [767]\n",
      "768 734 [768]\n",
      "769 3557 [769]\n",
      "770 10345 [770]\n",
      "771 809 [771]\n",
      "772 6295 [772]\n",
      "773 4065 [773]\n",
      "774 7160 [774]\n",
      "775 1197 [775]\n",
      "776 2620 [776]\n",
      "777 7406 [777]\n",
      "778 8407 [778]\n",
      "779 3081 [779]\n",
      "780 9692 [780]\n",
      "781 7097 [781]\n",
      "782 8370 [782]\n",
      "783 9740 [783]\n",
      "784 3231 [784]\n",
      "785 8201 [785]\n",
      "786 8056 [786]\n",
      "787 7832 [787]\n",
      "788 6121 [788]\n",
      "789 10014 [789]\n",
      "790 5018 [790]\n",
      "791 1374 [791]\n",
      "792 9272 [792]\n",
      "793 9262 [793]\n",
      "794 10101 [794]\n",
      "795 3680 [795]\n",
      "796 4679 [796]\n",
      "797 9969 [797]\n",
      "798 1649 [798]\n",
      "799 7672 [799]\n",
      "800 173 [800]\n",
      "801 3871 [801]\n",
      "802 7512 [802]\n",
      "803 781 [803]\n",
      "804 6875 [804]\n",
      "805 6802 [805]\n",
      "806 5183 [806]\n",
      "807 10633 [807]\n",
      "808 7570 [808]\n",
      "809 5510 [809]\n",
      "810 7116 [810]\n",
      "811 4054 [811]\n",
      "812 10002 [812]\n",
      "813 11133 [813]\n",
      "814 10530 [814]\n",
      "815 1688 [815]\n",
      "816 10955 [816]\n",
      "817 327 [817]\n",
      "818 6454 [818]\n",
      "819 4229 [819]\n",
      "820 5003 [820]\n",
      "821 8786 [821]\n",
      "822 1446 [822]\n",
      "823 4427 [823]\n",
      "824 4015 [824]\n",
      "825 6803 [825]\n",
      "826 9923 [826]\n",
      "827 9858 [827]\n",
      "828 9403 [828]\n",
      "829 6958 [829]\n",
      "830 9955 [830]\n",
      "831 3873 [831]\n",
      "832 11019 [832]\n",
      "833 813 [833]\n",
      "834 2597 [834]\n",
      "835 11308 [835]\n",
      "836 1948 [836]\n",
      "837 1438 [837]\n",
      "838 641 [838]\n",
      "839 5991 [839]\n",
      "840 9019 [840]\n",
      "841 7877 [841]\n",
      "842 4834 [842]\n",
      "843 10697 [843]\n",
      "844 8525 [844]\n",
      "845 2944 [845]\n",
      "846 4819 [846]\n",
      "847 9676 [847]\n",
      "848 8384 [848]\n",
      "849 9785 [849]\n",
      "850 9728 [850]\n",
      "851 4552 [851]\n",
      "852 4240 [852]\n",
      "853 3177 [853]\n",
      "854 4104 [854]\n",
      "855 10770 [855]\n",
      "856 9317 [856]\n",
      "857 646 [857]\n",
      "858 2655 [858]\n",
      "859 2961 [859]\n",
      "860 9222 [860]\n",
      "861 11551 [861]\n",
      "862 8584 [862]\n",
      "863 1646 [863]\n",
      "864 7871 [864]\n",
      "865 2640 [865]\n",
      "866 2300 [866]\n",
      "867 6401 [867]\n",
      "868 2977 [868]\n",
      "869 5170 [869]\n",
      "870 10812 [870]\n",
      "871 4126 [871]\n",
      "872 11225 [872]\n",
      "873 2400 [873]\n",
      "874 7376 [874]\n",
      "875 1202 [875]\n",
      "876 3756 [876]\n",
      "877 6256 [877]\n",
      "878 8040 [878]\n",
      "879 6274 [879]\n",
      "880 7577 [880]\n",
      "881 1603 [881]\n",
      "882 11128 [882]\n",
      "883 5654 [883]\n",
      "884 8544 [884]\n",
      "885 3613 [885]\n",
      "886 7140 [886]\n",
      "887 9832 [887]\n",
      "888 10895 [888]\n",
      "889 9968 [889]\n",
      "890 140 [890]\n",
      "891 2567 [891]\n",
      "892 10639 [892]\n",
      "893 8937 [893]\n",
      "894 10762 [894]\n",
      "895 4847 [895]\n",
      "896 1540 [896]\n",
      "897 10906 [897]\n",
      "898 1183 [898]\n",
      "899 3053 [899]\n",
      "900 8542 [900]\n",
      "901 11354 [901]\n",
      "902 5661 [902]\n",
      "903 10320 [903]\n",
      "904 1328 [904]\n",
      "905 11024 [905]\n",
      "906 4821 [906]\n",
      "907 4868 [907]\n",
      "908 897 [908]\n",
      "909 8700 [909]\n",
      "910 6041 [910]\n",
      "911 1006 [911]\n",
      "912 8982 [912]\n",
      "913 10884 [913]\n",
      "914 11115 [914]\n",
      "915 2353 [915]\n",
      "916 11290 [916]\n",
      "917 3102 [917]\n",
      "918 5414 [918]\n",
      "919 7569 [919]\n",
      "920 5591 [920]\n",
      "921 11641 [921]\n",
      "922 11552 [922]\n",
      "923 5369 [923]\n",
      "924 956 [924]\n",
      "925 9915 [925]\n",
      "926 1485 [926]\n",
      "927 9099 [927]\n",
      "928 2265 [928]\n",
      "929 3660 [929]\n",
      "930 3201 [930]\n",
      "931 5400 [931]\n",
      "932 7007 [932]\n",
      "933 9611 [933]\n",
      "934 4798 [934]\n",
      "935 5476 [935]\n",
      "936 6847 [936]\n",
      "937 4267 [937]\n",
      "938 9254 [938]\n",
      "939 873 [939]\n",
      "940 1687 [940]\n",
      "941 7466 [941]\n",
      "942 560 [942]\n",
      "943 1184 [943]\n",
      "944 988 [944]\n",
      "945 11282 [945]\n",
      "946 4271 [946]\n",
      "947 10938 [947]\n",
      "948 4953 [948]\n",
      "949 2831 [949]\n",
      "950 6884 [950]\n",
      "951 4384 [951]\n",
      "952 11584 [952]\n",
      "953 7070 [953]\n",
      "954 7458 [954]\n",
      "955 1829 [955]\n",
      "956 175 [956]\n",
      "957 10276 [957]\n",
      "958 400 [958]\n",
      "959 5338 [959]\n",
      "960 8159 [960]\n",
      "961 1849 [961]\n",
      "962 6973 [962]\n",
      "963 7366 [963]\n",
      "964 5074 [964]\n",
      "965 10378 [965]\n",
      "966 1833 [966]\n",
      "967 488 [967]\n",
      "968 2895 [968]\n",
      "969 8157 [969]\n",
      "970 9897 [970]\n",
      "971 2333 [971]\n",
      "972 5248 [972]\n",
      "973 8957 [973]\n",
      "974 9093 [974]\n",
      "975 6844 [975]\n",
      "976 1077 [976]\n",
      "977 57 [977]\n",
      "978 9637 [978]\n",
      "979 4857 [979]\n",
      "980 10943 [980]\n",
      "981 11053 [981]\n",
      "982 8765 [982]\n",
      "983 6489 [983]\n",
      "984 7409 [984]\n",
      "985 1869 [985]\n",
      "986 6119 [986]\n",
      "987 10676 [987]\n",
      "988 4142 [988]\n",
      "989 6352 [989]\n",
      "990 1583 [990]\n",
      "991 1325 [991]\n",
      "992 3236 [992]\n",
      "993 337 [993]\n",
      "994 3387 [994]\n",
      "995 5247 [995]\n",
      "996 1106 [996]\n",
      "997 7297 [997]\n",
      "998 6610 [998]\n",
      "999 11709 [999]\n",
      "1000 9764 [1000]\n",
      "1001 11288 [1001]\n",
      "1002 563 [1002]\n",
      "1003 430 [1003]\n",
      "1004 10183 [1004]\n",
      "1005 8399 [1005]\n",
      "1006 6681 [1006]\n",
      "1007 7392 [1007]\n",
      "1008 9678 [1008]\n",
      "1009 793 [1009]\n",
      "1010 3032 [1010]\n",
      "1011 9241 [1011]\n",
      "1012 4928 [1012]\n",
      "1013 7199 [1013]\n",
      "1014 9090 [1014]\n",
      "1015 8485 [1015]\n",
      "1016 2476 [1016]\n",
      "1017 735 [1017]\n",
      "1018 11440 [1018]\n",
      "1019 7947 [1019]\n",
      "1020 5108 [1020]\n",
      "1021 5150 [1021]\n",
      "1022 800 [1022]\n",
      "1023 8715 [1023]\n",
      "1024 6183 [1024]\n",
      "1025 9482 [1025]\n",
      "1026 8335 [1026]\n",
      "1027 10247 [1027]\n",
      "1028 10497 [1028]\n",
      "1029 8838 [1029]\n",
      "1030 1620 [1030]\n",
      "1031 990 [1031]\n",
      "1032 1675 [1032]\n",
      "1033 866 [1033]\n",
      "1034 4778 [1034]\n",
      "1035 888 [1035]\n",
      "1036 3564 [1036]\n",
      "1037 4 [1037]\n",
      "1038 6108 [1038]\n",
      "1039 17 [1039]\n",
      "1040 66 [1040]\n",
      "1041 4530 [1041]\n",
      "1042 7311 [1042]\n",
      "1043 3277 [1043]\n",
      "1044 1144 [1044]\n",
      "1045 9723 [1045]\n",
      "1046 6579 [1046]\n",
      "1047 692 [1047]\n",
      "1048 10052 [1048]\n",
      "1049 8716 [1049]\n",
      "1050 11188 [1050]\n",
      "1051 8270 [1051]\n",
      "1052 883 [1052]\n",
      "1053 11386 [1053]\n",
      "1054 8906 [1054]\n",
      "1055 6793 [1055]\n",
      "1056 7226 [1056]\n",
      "1057 8813 [1057]\n",
      "1058 5849 [1058]\n",
      "1059 8291 [1059]\n",
      "1060 473 [1060]\n",
      "1061 7202 [1061]\n",
      "1062 2371 [1062]\n",
      "1063 45 [1063]\n",
      "1064 6726 [1064]\n",
      "1065 8604 [1065]\n",
      "1066 11583 [1066]\n",
      "1067 5599 [1067]\n",
      "1068 73 [1068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069 3994 [1069]\n",
      "1070 595 [1070]\n",
      "1071 9260 [1071]\n",
      "1072 11299 [1072]\n",
      "1073 2849 [1073]\n",
      "1074 9484 [1074]\n",
      "1075 9316 [1075]\n",
      "1076 9571 [1076]\n",
      "1077 899 [1077]\n",
      "1078 11237 [1078]\n",
      "1079 402 [1079]\n",
      "1080 11633 [1080]\n",
      "1081 8497 [1081]\n",
      "1082 8211 [1082]\n",
      "1083 2520 [1083]\n",
      "1084 7186 [1084]\n",
      "1085 3262 [1085]\n",
      "1086 2534 [1086]\n",
      "1087 8701 [1087]\n",
      "1088 5683 [1088]\n",
      "1089 9490 [1089]\n",
      "1090 8812 [1090]\n",
      "1091 4112 [1091]\n",
      "1092 1504 [1092]\n",
      "1093 4436 [1093]\n",
      "1094 2691 [1094]\n",
      "1095 3091 [1095]\n",
      "1096 5636 [1096]\n",
      "1097 5361 [1097]\n",
      "1098 7015 [1098]\n",
      "1099 3507 [1099]\n",
      "1100 5703 [1100]\n",
      "1101 2383 [1101]\n",
      "1102 7483 [1102]\n",
      "1103 10699 [1103]\n",
      "1104 526 [1104]\n",
      "1105 8842 [1105]\n",
      "1106 120 [1106]\n",
      "1107 7156 [1107]\n",
      "1108 8575 [1108]\n",
      "1109 11301 [1109]\n",
      "1110 4522 [1110]\n",
      "1111 504 [1111]\n",
      "1112 6561 [1112]\n",
      "1113 1018 [1113]\n",
      "1114 5129 [1114]\n",
      "1115 5465 [1115]\n",
      "1116 9064 [1116]\n",
      "1117 2216 [1117]\n",
      "1118 5517 [1118]\n",
      "1119 3113 [1119]\n",
      "1120 11749 [1120]\n",
      "1121 9800 [1121]\n",
      "1122 4111 [1122]\n",
      "1123 7269 [1123]\n",
      "1124 10820 [1124]\n",
      "1125 8883 [1125]\n",
      "1126 19 [1126]\n",
      "1127 4409 [1127]\n",
      "1128 2068 [1128]\n",
      "1129 2424 [1129]\n",
      "1130 7749 [1130]\n",
      "1131 5572 [1131]\n",
      "1132 5634 [1132]\n",
      "1133 10139 [1133]\n",
      "1134 4509 [1134]\n",
      "1135 1223 [1135]\n",
      "1136 1621 [1136]\n",
      "1137 9778 [1137]\n",
      "1138 1079 [1138]\n",
      "1139 5603 [1139]\n",
      "1140 2758 [1140]\n",
      "1141 5831 [1141]\n",
      "1142 8074 [1142]\n",
      "1143 11349 [1143]\n",
      "1144 7647 [1144]\n",
      "1145 3935 [1145]\n",
      "1146 11374 [1146]\n",
      "1147 2910 [1147]\n",
      "1148 1920 [1148]\n",
      "1149 606 [1149]\n",
      "1150 304 [1150]\n",
      "1151 5304 [1151]\n",
      "1152 4458 [1152]\n",
      "1153 548 [1153]\n",
      "1154 7369 [1154]\n",
      "1155 4146 [1155]\n",
      "1156 2611 [1156]\n",
      "1157 1725 [1157]\n",
      "1158 6675 [1158]\n",
      "1159 7255 [1159]\n",
      "1160 2342 [1160]\n",
      "1161 8971 [1161]\n",
      "1162 10148 [1162]\n",
      "1163 6040 [1163]\n",
      "1164 6961 [1164]\n",
      "1165 5882 [1165]\n",
      "1166 905 [1166]\n",
      "1167 11697 [1167]\n",
      "1168 1277 [1168]\n",
      "1169 5238 [1169]\n",
      "1170 11632 [1170]\n",
      "1171 3724 [1171]\n",
      "1172 3611 [1172]\n",
      "1173 1789 [1173]\n",
      "1174 11730 [1174]\n",
      "1175 594 [1175]\n",
      "1176 5967 [1176]\n",
      "1177 4489 [1177]\n",
      "1178 7616 [1178]\n",
      "1179 5013 [1179]\n",
      "1180 4210 [1180]\n",
      "1181 5353 [1181]\n",
      "1182 9026 [1182]\n",
      "1183 6386 [1183]\n",
      "1184 5021 [1184]\n",
      "1185 2190 [1185]\n",
      "1186 7361 [1186]\n",
      "1187 834 [1187]\n",
      "1188 1416 [1188]\n",
      "1189 4189 [1189]\n",
      "1190 6599 [1190]\n",
      "1191 1801 [1191]\n",
      "1192 11544 [1192]\n",
      "1193 3859 [1193]\n",
      "1194 11758 [1194]\n",
      "1195 11666 [1195]\n",
      "1196 10286 [1196]\n",
      "1197 11318 [1197]\n",
      "1198 7317 [1198]\n",
      "1199 11618 [1199]\n",
      "1200 3654 [1200]\n",
      "1201 6979 [1201]\n",
      "1202 8007 [1202]\n",
      "1203 5610 [1203]\n",
      "1204 9895 [1204]\n",
      "1205 10460 [1205]\n",
      "1206 7797 [1206]\n",
      "1207 10042 [1207]\n",
      "1208 2713 [1208]\n",
      "1209 6631 [1209]\n",
      "1210 7703 [1210]\n",
      "1211 333 [1211]\n",
      "1212 10675 [1212]\n",
      "1213 332 [1213]\n",
      "1214 5889 [1214]\n",
      "1215 10236 [1215]\n",
      "1216 9769 [1216]\n",
      "1217 6729 [1217]\n",
      "1218 10024 [1218]\n",
      "1219 8278 [1219]\n",
      "1220 6984 [1220]\n",
      "1221 8369 [1221]\n",
      "1222 6846 [1222]\n",
      "1223 5366 [1223]\n",
      "1224 6177 [1224]\n",
      "1225 11197 [1225]\n",
      "1226 2607 [1226]\n",
      "1227 3747 [1227]\n",
      "1228 6477 [1228]\n",
      "1229 10170 [1229]\n",
      "1230 4756 [1230]\n",
      "1231 7584 [1231]\n",
      "1232 712 [1232]\n",
      "1233 1805 [1233]\n",
      "1234 10480 [1234]\n",
      "1235 4969 [1235]\n",
      "1236 11783 [1236]\n",
      "1237 1618 [1237]\n",
      "1238 7521 [1238]\n",
      "1239 1240 [1239]\n",
      "1240 7002 [1240]\n",
      "1241 3838 [1241]\n",
      "1242 2117 [1242]\n",
      "1243 7971 [1243]\n",
      "1244 2601 [1244]\n",
      "1245 4258 [1245]\n",
      "1246 9569 [1246]\n",
      "1247 5017 [1247]\n",
      "1248 7119 [1248]\n",
      "1249 10773 [1249]\n",
      "1250 9334 [1250]\n",
      "1251 5349 [1251]\n",
      "1252 10364 [1252]\n",
      "1253 11597 [1253]\n",
      "1254 2880 [1254]\n",
      "1255 280 [1255]\n",
      "1256 10791 [1256]\n",
      "1257 6478 [1257]\n",
      "1258 4564 [1258]\n",
      "1259 1251 [1259]\n",
      "1260 9426 [1260]\n",
      "1261 4034 [1261]\n",
      "1262 10737 [1262]\n",
      "1263 7419 [1263]\n",
      "1264 4951 [1264]\n",
      "1265 3745 [1265]\n",
      "1266 7959 [1266]\n",
      "1267 6168 [1267]\n",
      "1268 322 [1268]\n",
      "1269 6658 [1269]\n",
      "1270 2438 [1270]\n",
      "1271 6003 [1271]\n",
      "1272 7481 [1272]\n",
      "1273 11083 [1273]\n",
      "1274 4218 [1274]\n",
      "1275 4256 [1275]\n",
      "1276 5134 [1276]\n",
      "1277 2508 [1277]\n",
      "1278 10526 [1278]\n",
      "1279 10650 [1279]\n",
      "1280 10428 [1280]\n",
      "1281 6628 [1281]\n",
      "1282 3806 [1282]\n",
      "1283 2625 [1283]\n",
      "1284 3309 [1284]\n",
      "1285 7284 [1285]\n",
      "1286 3187 [1286]\n",
      "1287 1166 [1287]\n",
      "1288 4331 [1288]\n",
      "1289 4250 [1289]\n",
      "1290 384 [1290]\n",
      "1291 11247 [1291]\n",
      "1292 3458 [1292]\n",
      "1293 3886 [1293]\n",
      "1294 1454 [1294]\n",
      "1295 10000 [1295]\n",
      "1296 1590 [1296]\n",
      "1297 7740 [1297]\n",
      "1298 10434 [1298]\n",
      "1299 10167 [1299]\n",
      "1300 1602 [1300]\n",
      "1301 469 [1301]\n",
      "1302 52 [1302]\n",
      "1303 8543 [1303]\n",
      "1304 5474 [1304]\n",
      "1305 2010 [1305]\n",
      "1306 7994 [1306]\n",
      "1307 10261 [1307]\n",
      "1308 8606 [1308]\n",
      "1309 3319 [1309]\n",
      "1310 1989 [1310]\n",
      "1311 11609 [1311]\n",
      "1312 5377 [1312]\n",
      "1313 4077 [1313]\n",
      "1314 835 [1314]\n",
      "1315 10151 [1315]\n",
      "1316 4811 [1316]\n",
      "1317 10716 [1317]\n",
      "1318 7112 [1318]\n",
      "1319 5619 [1319]\n",
      "1320 7555 [1320]\n",
      "1321 2707 [1321]\n",
      "1322 10632 [1322]\n",
      "1323 11626 [1323]\n",
      "1324 3853 [1324]\n",
      "1325 3848 [1325]\n",
      "1326 3965 [1326]\n",
      "1327 8311 [1327]\n",
      "1328 9323 [1328]\n",
      "1329 7698 [1329]\n",
      "1330 9722 [1330]\n",
      "1331 9023 [1331]\n",
      "1332 574 [1332]\n",
      "1333 1919 [1333]\n",
      "1334 2088 [1334]\n",
      "1335 277 [1335]\n",
      "1336 10604 [1336]\n",
      "1337 196 [1337]\n",
      "1338 2431 [1338]\n",
      "1339 9225 [1339]\n",
      "1340 4237 [1340]\n",
      "1341 5753 [1341]\n",
      "1342 7669 [1342]\n",
      "1343 1019 [1343]\n",
      "1344 2070 [1344]\n",
      "1345 11557 [1345]\n",
      "1346 7815 [1346]\n",
      "1347 2102 [1347]\n",
      "1348 10793 [1348]\n",
      "1349 1823 [1349]\n",
      "1350 6110 [1350]\n",
      "1351 1713 [1351]\n",
      "1352 9105 [1352]\n",
      "1353 10359 [1353]\n",
      "1354 586 [1354]\n",
      "1355 11239 [1355]\n",
      "1356 7078 [1356]\n",
      "1357 3966 [1357]\n",
      "1358 3771 [1358]\n",
      "1359 3220 [1359]\n",
      "1360 4391 [1360]\n",
      "1361 5116 [1361]\n",
      "1362 7087 [1362]\n",
      "1363 7868 [1363]\n",
      "1364 1055 [1364]\n",
      "1365 5036 [1365]\n",
      "1366 5162 [1366]\n",
      "1367 7363 [1367]\n",
      "1368 11413 [1368]\n",
      "1369 9684 [1369]\n",
      "1370 1039 [1370]\n",
      "1371 7823 [1371]\n",
      "1372 3691 [1372]\n",
      "1373 3568 [1373]\n",
      "1374 9664 [1374]\n",
      "1375 1673 [1375]\n",
      "1376 7027 [1376]\n",
      "1377 5827 [1377]\n",
      "1378 6564 [1378]\n",
      "1379 9928 [1379]\n",
      "1380 4442 [1380]\n",
      "1381 693 [1381]\n",
      "1382 10621 [1382]\n",
      "1383 7607 [1383]\n",
      "1384 6767 [1384]\n",
      "1385 7731 [1385]\n",
      "1386 10685 [1386]\n",
      "1387 9803 [1387]\n",
      "1388 6904 [1388]\n",
      "1389 10509 [1389]\n",
      "1390 1932 [1390]\n",
      "1391 7249 [1391]\n",
      "1392 9965 [1392]\n",
      "1393 2084 [1393]\n",
      "1394 1786 [1394]\n",
      "1395 1676 [1395]\n",
      "1396 7201 [1396]\n",
      "1397 6502 [1397]\n",
      "1398 7965 [1398]\n",
      "1399 6166 [1399]\n",
      "1400 2633 [1400]\n",
      "1401 3534 [1401]\n",
      "1402 6750 [1402]\n",
      "1403 4028 [1403]\n",
      "1404 6181 [1404]\n",
      "1405 6665 [1405]\n",
      "1406 3140 [1406]\n",
      "1407 10919 [1407]\n",
      "1408 3208 [1408]\n",
      "1409 5210 [1409]\n",
      "1410 3818 [1410]\n",
      "1411 11359 [1411]\n",
      "1412 5581 [1412]\n",
      "1413 4056 [1413]\n",
      "1414 8320 [1414]\n",
      "1415 3947 [1415]\n",
      "1416 3344 [1416]\n",
      "1417 1025 [1417]\n",
      "1418 1720 [1418]\n",
      "1419 8749 [1419]\n",
      "1420 10799 [1420]\n",
      "1421 2344 [1421]\n",
      "1422 1772 [1422]\n",
      "1423 3160 [1423]\n",
      "1424 10501 [1424]\n",
      "1425 7429 [1425]\n",
      "1426 2757 [1426]\n",
      "1427 9117 [1427]\n",
      "1428 10246 [1428]\n",
      "1429 10491 [1429]\n",
      "1430 6457 [1430]\n",
      "1431 7565 [1431]\n",
      "1432 8981 [1432]\n",
      "1433 8280 [1433]\n",
      "1434 11346 [1434]\n",
      "1435 8043 [1435]\n",
      "1436 6914 [1436]\n",
      "1437 5843 [1437]\n",
      "1438 9495 [1438]\n",
      "1439 5091 [1439]\n",
      "1440 10011 [1440]\n",
      "1441 9344 [1441]\n",
      "1442 11704 [1442]\n",
      "1443 3244 [1443]\n",
      "1444 10017 [1444]\n",
      "1445 7107 [1445]\n",
      "1446 7604 [1446]\n",
      "1447 4737 [1447]\n",
      "1448 11581 [1448]\n",
      "1449 205 [1449]\n",
      "1450 1250 [1450]\n",
      "1451 9184 [1451]\n",
      "1452 8266 [1452]\n",
      "1453 8781 [1453]\n",
      "1454 7697 [1454]\n",
      "1455 9413 [1455]\n",
      "1456 10561 [1456]\n",
      "1457 10759 [1457]\n",
      "1458 822 [1458]\n",
      "1459 3430 [1459]\n",
      "1460 9410 [1460]\n",
      "1461 3015 [1461]\n",
      "1462 1952 [1462]\n",
      "1463 2250 [1463]\n",
      "1464 2227 [1464]\n",
      "1465 7826 [1465]\n",
      "1466 7822 [1466]\n",
      "1467 9500 [1467]\n",
      "1468 522 [1468]\n",
      "1469 3351 [1469]\n",
      "1470 7089 [1470]\n",
      "1471 1452 [1471]\n",
      "1472 4611 [1472]\n",
      "1473 2871 [1473]\n",
      "1474 11680 [1474]\n",
      "1475 7398 [1475]\n",
      "1476 6242 [1476]\n",
      "1477 2049 [1477]\n",
      "1478 6237 [1478]\n",
      "1479 6417 [1479]\n",
      "1480 1050 [1480]\n",
      "1481 2889 [1481]\n",
      "1482 4764 [1482]\n",
      "1483 4327 [1483]\n",
      "1484 11355 [1484]\n",
      "1485 6677 [1485]\n",
      "1486 9552 [1486]\n",
      "1487 8946 [1487]\n",
      "1488 5960 [1488]\n",
      "1489 3864 [1489]\n",
      "1490 3307 [1490]\n",
      "1491 4557 [1491]\n",
      "1492 290 [1492]\n",
      "1493 620 [1493]\n",
      "1494 4944 [1494]\n",
      "1495 1407 [1495]\n",
      "1496 10833 [1496]\n",
      "1497 10473 [1497]\n",
      "1498 1853 [1498]\n",
      "1499 5760 [1499]\n",
      "1500 1402 [1500]\n",
      "1501 1244 [1501]\n",
      "1502 3434 [1502]\n",
      "1503 4812 [1503]\n",
      "1504 4881 [1504]\n",
      "1505 10813 [1505]\n",
      "1506 9364 [1506]\n",
      "1507 431 [1507]\n",
      "1508 9336 [1508]\n",
      "1509 8410 [1509]\n",
      "1510 8393 [1510]\n",
      "1511 11764 [1511]\n",
      "1512 5268 [1512]\n",
      "1513 2112 [1513]\n",
      "1514 6287 [1514]\n",
      "1515 8391 [1515]\n",
      "1516 2942 [1516]\n",
      "1517 8405 [1517]\n",
      "1518 9759 [1518]\n",
      "1519 1929 [1519]\n",
      "1520 3508 [1520]\n",
      "1521 6346 [1521]\n",
      "1522 10601 [1522]\n",
      "1523 4630 [1523]\n",
      "1524 6532 [1524]\n",
      "1525 5602 [1525]\n",
      "1526 6081 [1526]\n",
      "1527 3872 [1527]\n",
      "1528 10853 [1528]\n",
      "1529 7928 [1529]\n",
      "1530 11338 [1530]\n",
      "1531 6753 [1531]\n",
      "1532 5142 [1532]\n",
      "1533 7001 [1533]\n",
      "1534 4405 [1534]\n",
      "1535 3604 [1535]\n",
      "1536 8009 [1536]\n",
      "1537 5912 [1537]\n",
      "1538 6756 [1538]\n",
      "1539 3865 [1539]\n",
      "1540 1026 [1540]\n",
      "1541 9929 [1541]\n",
      "1542 1105 [1542]\n",
      "1543 6217 [1543]\n",
      "1544 6027 [1544]\n",
      "1545 5562 [1545]\n",
      "1546 10125 [1546]\n",
      "1547 5743 [1547]\n",
      "1548 1511 [1548]\n",
      "1549 1451 [1549]\n",
      "1550 6102 [1550]\n",
      "1551 112 [1551]\n",
      "1552 3768 [1552]\n",
      "1553 6170 [1553]\n",
      "1554 729 [1554]\n",
      "1555 9798 [1555]\n",
      "1556 8116 [1556]\n",
      "1557 4638 [1557]\n",
      "1558 10570 [1558]\n",
      "1559 9824 [1559]\n",
      "1560 1940 [1560]\n",
      "1561 6705 [1561]\n",
      "1562 4165 [1562]\n",
      "1563 2744 [1563]\n",
      "1564 10190 [1564]\n",
      "1565 4992 [1565]\n",
      "1566 11464 [1566]\n",
      "1567 5423 [1567]\n",
      "1568 7489 [1568]\n",
      "1569 4742 [1569]\n",
      "1570 4766 [1570]\n",
      "1571 11595 [1571]\n",
      "1572 2740 [1572]\n",
      "1573 10669 [1573]\n",
      "1574 4528 [1574]\n",
      "1575 7715 [1575]\n",
      "1576 2536 [1576]\n",
      "1577 9879 [1577]\n",
      "1578 7563 [1578]\n",
      "1579 7638 [1579]\n",
      "1580 5687 [1580]\n",
      "1581 4270 [1581]\n",
      "1582 3545 [1582]\n",
      "1583 8859 [1583]\n",
      "1584 257 [1584]\n",
      "1585 9987 [1585]\n",
      "1586 7088 [1586]\n",
      "1587 9650 [1587]\n",
      "1588 2349 [1588]\n",
      "1589 3598 [1589]\n",
      "1590 1686 [1590]\n",
      "1591 3176 [1591]\n",
      "1592 4886 [1592]\n",
      "1593 11690 [1593]\n",
      "1594 3333 [1594]\n",
      "1595 5564 [1595]\n",
      "1596 2064 [1596]\n",
      "1597 1327 [1597]\n",
      "1598 8400 [1598]\n",
      "1599 5154 [1599]\n",
      "1600 6696 [1600]\n",
      "1601 2115 [1601]\n",
      "1602 1577 [1602]\n",
      "1603 3172 [1603]\n",
      "1604 4444 [1604]\n",
      "1605 8682 [1605]\n",
      "1606 7653 [1606]\n",
      "1607 6248 [1607]\n",
      "1608 6506 [1608]\n",
      "1609 8305 [1609]\n",
      "1610 11293 [1610]\n",
      "1611 11780 [1611]\n",
      "1612 1561 [1612]\n",
      "1613 989 [1613]\n",
      "1614 4849 [1614]\n",
      "1615 11605 [1615]\n",
      "1616 2643 [1616]\n",
      "1617 3462 [1617]\n",
      "1618 7810 [1618]\n",
      "1619 1289 [1619]\n",
      "1620 5645 [1620]\n",
      "1621 2705 [1621]\n",
      "1622 3166 [1622]\n",
      "1623 6276 [1623]\n",
      "1624 1956 [1624]\n",
      "1625 9856 [1625]\n",
      "1626 7640 [1626]\n",
      "1627 5929 [1627]\n",
      "1628 34 [1628]\n",
      "1629 8244 [1629]\n",
      "1630 9414 [1630]\n",
      "1631 6420 [1631]\n",
      "1632 2033 [1632]\n",
      "1633 5358 [1633]\n",
      "1634 2746 [1634]\n",
      "1635 10709 [1635]\n",
      "1636 2663 [1636]\n",
      "1637 4898 [1637]\n",
      "1638 2406 [1638]\n",
      "1639 6752 [1639]\n",
      "1640 1570 [1640]\n",
      "1641 9487 [1641]\n",
      "1642 6988 [1642]\n",
      "1643 139 [1643]\n",
      "1644 9040 [1644]\n",
      "1645 11402 [1645]\n",
      "1646 9625 [1646]\n",
      "1647 8217 [1647]\n",
      "1648 1228 [1648]\n",
      "1649 5791 [1649]\n",
      "1650 6469 [1650]\n",
      "1651 10703 [1651]\n",
      "1652 8171 [1652]\n",
      "1653 4960 [1653]\n",
      "1654 10952 [1654]\n",
      "1655 7875 [1655]\n",
      "1656 8179 [1656]\n",
      "1657 9103 [1657]\n",
      "1658 1345 [1658]\n",
      "1659 6818 [1659]\n",
      "1660 7712 [1660]\n",
      "1661 6751 [1661]\n",
      "1662 1348 [1662]\n",
      "1663 10367 [1663]\n",
      "1664 1653 [1664]\n",
      "1665 5775 [1665]\n",
      "1666 10406 [1666]\n",
      "1667 3544 [1667]\n",
      "1668 5962 [1668]\n",
      "1669 3890 [1669]\n",
      "1670 11455 [1670]\n",
      "1671 2535 [1671]\n",
      "1672 5689 [1672]\n",
      "1673 5404 [1673]\n",
      "1674 9863 [1674]\n",
      "1675 3517 [1675]\n",
      "1676 2191 [1676]\n",
      "1677 9359 [1677]\n",
      "1678 7526 [1678]\n",
      "1679 11094 [1679]\n",
      "1680 7237 [1680]\n",
      "1681 1834 [1681]\n",
      "1682 10348 [1682]\n",
      "1683 1439 [1683]\n",
      "1684 2553 [1684]\n",
      "1685 5863 [1685]\n",
      "1686 2843 [1686]\n",
      "1687 8509 [1687]\n",
      "1688 8001 [1688]\n",
      "1689 11737 [1689]\n",
      "1690 252 [1690]\n",
      "1691 3025 [1691]\n",
      "1692 598 [1692]\n",
      "1693 10523 [1693]\n",
      "1694 5810 [1694]\n",
      "1695 2924 [1695]\n",
      "1696 11187 [1696]\n",
      "1697 4652 [1697]\n",
      "1698 2778 [1698]\n",
      "1699 8809 [1699]\n",
      "1700 5763 [1700]\n",
      "1701 5309 [1701]\n",
      "1702 11733 [1702]\n",
      "1703 2377 [1703]\n",
      "1704 2428 [1704]\n",
      "1705 8375 [1705]\n",
      "1706 9518 [1706]\n",
      "1707 3793 [1707]\n",
      "1708 8665 [1708]\n",
      "1709 11423 [1709]\n",
      "1710 5877 [1710]\n",
      "1711 4655 [1711]\n",
      "1712 432 [1712]\n",
      "1713 1331 [1713]\n",
      "1714 10429 [1714]\n",
      "1715 1780 [1715]\n",
      "1716 3503 [1716]\n",
      "1717 9145 [1717]\n",
      "1718 1286 [1718]\n",
      "1719 2343 [1719]\n",
      "1720 4512 [1720]\n",
      "1721 10894 [1721]\n",
      "1722 6513 [1722]\n",
      "1723 11362 [1723]\n",
      "1724 5137 [1724]\n",
      "1725 10369 [1725]\n",
      "1726 5824 [1726]\n",
      "1727 167 [1727]\n",
      "1728 6030 [1728]\n",
      "1729 8926 [1729]\n",
      "1730 5744 [1730]\n",
      "1731 8818 [1731]\n",
      "1732 8895 [1732]\n",
      "1733 9963 [1733]\n",
      "1734 8601 [1734]\n",
      "1735 4031 [1735]\n",
      "1736 8205 [1736]\n",
      "1737 5742 [1737]\n",
      "1738 7699 [1738]\n",
      "1739 7374 [1739]\n",
      "1740 8412 [1740]\n",
      "1741 8143 [1741]\n",
      "1742 2572 [1742]\n",
      "1743 10318 [1743]\n",
      "1744 6190 [1744]\n",
      "1745 10931 [1745]\n",
      "1746 11492 [1746]\n",
      "1747 6542 [1747]\n",
      "1748 4438 [1748]\n",
      "1749 2622 [1749]\n",
      "1750 2266 [1750]\n",
      "1751 1509 [1751]\n",
      "1752 5987 [1752]\n",
      "1753 6987 [1753]\n",
      "1754 7874 [1754]\n",
      "1755 8365 [1755]\n",
      "1756 4182 [1756]\n",
      "1757 5690 [1757]\n",
      "1758 4018 [1758]\n",
      "1759 4775 [1759]\n",
      "1760 9638 [1760]\n",
      "1761 3156 [1761]\n",
      "1762 6051 [1762]\n",
      "1763 8583 [1763]\n",
      "1764 6983 [1764]\n",
      "1765 6701 [1765]\n",
      "1766 3022 [1766]\n",
      "1767 7336 [1767]\n",
      "1768 1281 [1768]\n",
      "1769 4700 [1769]\n",
      "1770 3615 [1770]\n",
      "1771 10100 [1771]\n",
      "1772 4169 [1772]\n",
      "1773 2915 [1773]\n",
      "1774 7146 [1774]\n",
      "1775 7184 [1775]\n",
      "1776 10925 [1776]\n",
      "1777 1052 [1777]\n",
      "1778 1109 [1778]\n",
      "1779 671 [1779]\n",
      "1780 283 [1780]\n",
      "1781 3274 [1781]\n",
      "1782 48 [1782]\n",
      "1783 7286 [1783]\n",
      "1784 2748 [1784]\n",
      "1785 1708 [1785]\n",
      "1786 4125 [1786]\n",
      "1787 9909 [1787]\n",
      "1788 8844 [1788]\n",
      "1789 1584 [1789]\n",
      "1790 9814 [1790]\n",
      "1791 3112 [1791]\n",
      "1792 4113 [1792]\n",
      "1793 2346 [1793]\n",
      "1794 8465 [1794]\n",
      "1795 6533 [1795]\n",
      "1796 1771 [1796]\n",
      "1797 2955 [1797]\n",
      "1798 8168 [1798]\n",
      "1799 7177 [1799]\n",
      "1800 6016 [1800]\n",
      "1801 818 [1801]\n",
      "1802 4243 [1802]\n",
      "1803 6831 [1803]\n",
      "1804 828 [1804]\n",
      "1805 279 [1805]\n",
      "1806 10048 [1806]\n",
      "1807 6141 [1807]\n",
      "1808 2738 [1808]\n",
      "1809 1376 [1809]\n",
      "1810 1279 [1810]\n",
      "1811 10060 [1811]\n",
      "1812 8338 [1812]\n",
      "1813 135 [1813]\n",
      "1814 7817 [1814]\n",
      "1815 3459 [1815]\n",
      "1816 2439 [1816]\n",
      "1817 10419 [1817]\n",
      "1818 8566 [1818]\n",
      "1819 5697 [1819]\n",
      "1820 7380 [1820]\n",
      "1821 1756 [1821]\n",
      "1822 4922 [1822]\n",
      "1823 6389 [1823]\n",
      "1824 2054 [1824]\n",
      "1825 709 [1825]\n",
      "1826 11064 [1826]\n",
      "1827 5461 [1827]\n",
      "1828 10381 [1828]\n",
      "1829 10086 [1829]\n",
      "1830 9306 [1830]\n",
      "1831 8373 [1831]\n",
      "1832 8101 [1832]\n",
      "1833 6742 [1833]\n",
      "1834 10387 [1834]\n",
      "1835 6357 [1835]\n",
      "1836 11278 [1836]\n",
      "1837 2396 [1837]\n",
      "1838 9208 [1838]\n",
      "1839 9264 [1839]\n",
      "1840 2518 [1840]\n",
      "1841 4305 [1841]\n",
      "1842 3714 [1842]\n",
      "1843 6245 [1843]\n",
      "1844 3067 [1844]\n",
      "1845 9240 [1845]\n",
      "1846 2143 [1846]\n",
      "1847 8974 [1847]\n",
      "1848 6870 [1848]\n",
      "1849 8367 [1849]\n",
      "1850 9561 [1850]\n",
      "1851 5558 [1851]\n",
      "1852 9708 [1852]\n",
      "1853 5211 [1853]\n",
      "1854 2505 [1854]\n",
      "1855 10033 [1855]\n",
      "1856 5778 [1856]\n",
      "1857 3269 [1857]\n",
      "1858 1354 [1858]\n",
      "1859 3173 [1859]\n",
      "1860 5284 [1860]\n",
      "1861 4976 [1861]\n",
      "1862 2234 [1862]\n",
      "1863 5062 [1863]\n",
      "1864 946 [1864]\n",
      "1865 1309 [1865]\n",
      "1866 7274 [1866]\n",
      "1867 7372 [1867]\n",
      "1868 6006 [1868]\n",
      "1869 2500 [1869]\n",
      "1870 11635 [1870]\n",
      "1871 8561 [1871]\n",
      "1872 3142 [1872]\n",
      "1873 4687 [1873]\n",
      "1874 4353 [1874]\n",
      "1875 5356 [1875]\n",
      "1876 5111 [1876]\n",
      "1877 8706 [1877]\n",
      "1878 5240 [1878]\n",
      "1879 3842 [1879]\n",
      "1880 5500 [1880]\n",
      "1881 3814 [1881]\n",
      "1882 2997 [1882]\n",
      "1883 8434 [1883]\n",
      "1884 9349 [1884]\n",
      "1885 267 [1885]\n",
      "1886 7271 [1886]\n",
      "1887 5199 [1887]\n",
      "1888 6597 [1888]\n",
      "1889 984 [1889]\n",
      "1890 8768 [1890]\n",
      "1891 790 [1891]\n",
      "1892 628 [1892]\n",
      "1893 460 [1893]\n",
      "1894 3195 [1894]\n",
      "1895 8461 [1895]\n",
      "1896 792 [1896]\n",
      "1897 8521 [1897]\n",
      "1898 3889 [1898]\n",
      "1899 3686 [1899]\n",
      "1900 7074 [1900]\n",
      "1901 3823 [1901]\n",
      "1902 1206 [1902]\n",
      "1903 7625 [1903]\n",
      "1904 3045 [1904]\n",
      "1905 1200 [1905]\n",
      "1906 6447 [1906]\n",
      "1907 11695 [1907]\n",
      "1908 8186 [1908]\n",
      "1909 5782 [1909]\n",
      "1910 7030 [1910]\n",
      "1911 7344 [1911]\n",
      "1912 6654 [1912]\n",
      "1913 681 [1913]\n",
      "1914 3400 [1914]\n",
      "1915 8804 [1915]\n",
      "1916 3968 [1916]\n",
      "1917 10893 [1917]\n",
      "1918 1585 [1918]\n",
      "1919 514 [1919]\n",
      "1920 922 [1920]\n",
      "1921 1099 [1921]\n",
      "1922 1353 [1922]\n",
      "1923 7716 [1923]\n",
      "1924 9655 [1924]\n",
      "1925 3727 [1925]\n",
      "1926 6428 [1926]\n",
      "1927 5266 [1927]\n",
      "1928 4579 [1928]\n",
      "1929 4867 [1929]\n",
      "1930 10965 [1930]\n",
      "1931 1038 [1931]\n",
      "1932 2016 [1932]\n",
      "1933 7431 [1933]\n",
      "1934 9280 [1934]\n",
      "1935 11074 [1935]\n",
      "1936 3249 [1936]\n",
      "1937 10581 [1937]\n",
      "1938 9321 [1938]\n",
      "1939 863 [1939]\n",
      "1940 8567 [1940]\n",
      "1941 9420 [1941]\n",
      "1942 2489 [1942]\n",
      "1943 2594 [1943]\n",
      "1944 9443 [1944]\n",
      "1945 3932 [1945]\n",
      "1946 4014 [1946]\n",
      "1947 5010 [1947]\n",
      "1948 11508 [1948]\n",
      "1949 9372 [1949]\n",
      "1950 6937 [1950]\n",
      "1951 6067 [1951]\n",
      "1952 6361 [1952]\n",
      "1953 6837 [1953]\n",
      "1954 1877 [1954]\n",
      "1955 3342 [1955]\n",
      "1956 8193 [1956]\n",
      "1957 7108 [1957]\n",
      "1958 6785 [1958]\n",
      "1959 357 [1959]\n",
      "1960 8037 [1960]\n",
      "1961 5868 [1961]\n",
      "1962 1973 [1962]\n",
      "1963 5392 [1963]\n",
      "1964 4038 [1964]\n",
      "1965 11292 [1965]\n",
      "1966 3688 [1966]\n",
      "1967 5942 [1967]\n",
      "1968 10582 [1968]\n",
      "1969 2432 [1969]\n",
      "1970 9699 [1970]\n",
      "1971 8942 [1971]\n",
      "1972 1746 [1972]\n",
      "1973 7615 [1973]\n",
      "1974 5173 [1974]\n",
      "1975 4690 [1975]\n",
      "1976 7899 [1976]\n",
      "1977 10551 [1977]\n",
      "1978 9039 [1978]\n",
      "1979 8888 [1979]\n",
      "1980 273 [1980]\n",
      "1981 10156 [1981]\n",
      "1982 4091 [1982]\n",
      "1983 5480 [1983]\n",
      "1984 4956 [1984]\n",
      "1985 3689 [1985]\n",
      "1986 3955 [1986]\n",
      "1987 3302 [1987]\n",
      "1988 7603 [1988]\n",
      "1989 1812 [1989]\n",
      "1990 8675 [1990]\n",
      "1991 1830 [1991]\n",
      "1992 6660 [1992]\n",
      "1993 11192 [1993]\n",
      "1994 1084 [1994]\n",
      "1995 1971 [1995]\n",
      "1996 1571 [1996]\n",
      "1997 9939 [1997]\n",
      "1998 9694 [1998]\n",
      "1999 4095 [1999]\n",
      "2000 8255 [2000]\n",
      "2001 334 [2001]\n",
      "2002 11681 [2002]\n",
      "2003 10840 [2003]\n",
      "2004 6714 [2004]\n",
      "2005 10682 [2005]\n",
      "2006 3983 [2006]\n",
      "2007 11165 [2007]\n",
      "2008 4654 [2008]\n",
      "2009 8965 [2009]\n",
      "2010 10734 [2010]\n",
      "2011 8263 [2011]\n",
      "2012 6488 [2012]\n",
      "2013 11509 [2013]\n",
      "2014 2196 [2014]\n",
      "2015 10726 [2015]\n",
      "2016 3831 [2016]\n",
      "2017 2776 [2017]\n",
      "2018 10145 [2018]\n",
      "2019 5647 [2019]\n",
      "2020 5770 [2020]\n",
      "2021 4899 [2021]\n",
      "2022 7992 [2022]\n",
      "2023 11568 [2023]\n",
      "2024 4156 [2024]\n",
      "2025 271 [2025]\n",
      "2026 10887 [2026]\n",
      "2027 8672 [2027]\n",
      "2028 4155 [2028]\n",
      "2029 1154 [2029]\n",
      "2030 1739 [2030]\n",
      "2031 3361 [2031]\n",
      "2032 10450 [2032]\n",
      "2033 11071 [2033]\n",
      "2034 9166 [2034]\n",
      "2035 11564 [2035]\n",
      "2036 6415 [2036]\n",
      "2037 4558 [2037]\n",
      "2038 10664 [2038]\n",
      "2039 4682 [2039]\n",
      "2040 812 [2040]\n",
      "2041 8122 [2041]\n",
      "2042 1913 [2042]\n",
      "2043 8915 [2043]\n",
      "2044 11539 [2044]\n",
      "2045 3042 [2045]\n",
      "2046 1406 [2046]\n",
      "2047 50 [2047]\n",
      "2048 954 [2048]\n",
      "2049 8934 [2049]\n",
      "2050 4452 [2050]\n",
      "2051 10073 [2051]\n",
      "2052 9574 [2052]\n",
      "2053 2052 [2053]\n",
      "2054 2483 [2054]\n",
      "2055 3485 [2055]\n",
      "2056 4971 [2056]\n",
      "2057 6153 [2057]\n",
      "2058 2355 [2058]\n",
      "2059 7034 [2059]\n",
      "2060 9460 [2060]\n",
      "2061 4566 [2061]\n",
      "2062 11693 [2062]\n",
      "2063 3429 [2063]\n",
      "2064 656 [2064]\n",
      "2065 3228 [2065]\n",
      "2066 7968 [2066]\n",
      "2067 6439 [2067]\n",
      "2068 4464 [2068]\n",
      "2069 9615 [2069]\n",
      "2070 7196 [2070]\n",
      "2071 10862 [2071]\n",
      "2072 2753 [2072]\n",
      "2073 4996 [2073]\n",
      "2074 6150 [2074]\n",
      "2075 2771 [2075]\n",
      "2076 312 [2076]\n",
      "2077 11158 [2077]\n",
      "2078 464 [2078]\n",
      "2079 11606 [2079]\n",
      "2080 9852 [2080]\n",
      "2081 3737 [2081]\n",
      "2082 392 [2082]\n",
      "2083 10085 [2083]\n",
      "2084 6810 [2084]\n",
      "2085 7758 [2085]\n",
      "2086 8128 [2086]\n",
      "2087 10873 [2087]\n",
      "2088 2067 [2088]\n",
      "2089 5878 [2089]\n",
      "2090 10198 [2090]\n",
      "2091 5303 [2091]\n",
      "2092 4233 [2092]\n",
      "2093 3617 [2093]\n",
      "2094 2984 [2094]\n",
      "2095 8262 [2095]\n",
      "2096 2501 [2096]\n",
      "2097 9226 [2097]\n",
      "2098 2303 [2098]\n",
      "2099 5481 [2099]\n",
      "2100 5066 [2100]\n",
      "2101 5731 [2101]\n",
      "2102 7934 [2102]\n",
      "2103 4860 [2103]\n",
      "2104 6369 [2104]\n",
      "2105 635 [2105]\n",
      "2106 8045 [2106]\n",
      "2107 5915 [2107]\n",
      "2108 5381 [2108]\n",
      "2109 8088 [2109]\n",
      "2110 2101 [2110]\n",
      "2111 4344 [2111]\n",
      "2112 4116 [2112]\n",
      "2113 7253 [2113]\n",
      "2114 5556 [2114]\n",
      "2115 1170 [2115]\n",
      "2116 6804 [2116]\n",
      "2117 475 [2117]\n",
      "2118 5600 [2118]\n",
      "2119 8493 [2119]\n",
      "2120 9584 [2120]\n",
      "2121 2636 [2121]\n",
      "2122 8586 [2122]\n",
      "2123 4340 [2123]\n",
      "2124 1336 [2124]\n",
      "2125 4755 [2125]\n",
      "2126 6207 [2126]\n",
      "2127 8565 [2127]\n",
      "2128 7425 [2128]\n",
      "2129 11571 [2129]\n",
      "2130 6668 [2130]\n",
      "2131 6394 [2131]\n",
      "2132 6212 [2132]\n",
      "2133 10780 [2133]\n",
      "2134 10432 [2134]\n",
      "2135 9730 [2135]\n",
      "2136 8290 [2136]\n",
      "2137 754 [2137]\n",
      "2138 2683 [2138]\n",
      "2139 10201 [2139]\n",
      "2140 3515 [2140]\n",
      "2141 10559 [2141]\n",
      "2142 9310 [2142]\n",
      "2143 3339 [2143]\n",
      "2144 4723 [2144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145 6107 [2145]\n",
      "2146 5795 [2146]\n",
      "2147 2747 [2147]\n",
      "2148 1014 [2148]\n",
      "2149 11220 [2149]\n",
      "2150 5095 [2150]\n",
      "2151 6470 [2151]\n",
      "2152 1897 [2152]\n",
      "2153 8868 [2153]\n",
      "2154 3362 [2154]\n",
      "2155 11243 [2155]\n",
      "2156 5466 [2156]\n",
      "2157 2325 [2157]\n",
      "2158 969 [2158]\n",
      "2159 6895 [2159]\n",
      "2160 4289 [2160]\n",
      "2161 490 [2161]\n",
      "2162 10323 [2162]\n",
      "2163 7038 [2163]\n",
      "2164 4135 [2164]\n",
      "2165 5236 [2165]\n",
      "2166 422 [2166]\n",
      "2167 4285 [2167]\n",
      "2168 6924 [2168]\n",
      "2169 10264 [2169]\n",
      "2170 1119 [2170]\n",
      "2171 1573 [2171]\n",
      "2172 7100 [2172]\n",
      "2173 10816 [2173]\n",
      "2174 6023 [2174]\n",
      "2175 7701 [2175]\n",
      "2176 3786 [2176]\n",
      "2177 4768 [2177]\n",
      "2178 11005 [2178]\n",
      "2179 4382 [2179]\n",
      "2180 8354 [2180]\n",
      "2181 5911 [2181]\n",
      "2182 1488 [2182]\n",
      "2183 2810 [2183]\n",
      "2184 11344 [2184]\n",
      "2185 10122 [2185]\n",
      "2186 4848 [2186]\n",
      "2187 7542 [2187]\n",
      "2188 11720 [2188]\n",
      "2189 10417 [2189]\n",
      "2190 2687 [2190]\n",
      "2191 10026 [2191]\n",
      "2192 6282 [2192]\n",
      "2193 5901 [2193]\n",
      "2194 1352 [2194]\n",
      "2195 6757 [2195]\n",
      "2196 1580 [2196]\n",
      "2197 496 [2197]\n",
      "2198 4541 [2198]\n",
      "2199 4880 [2199]\n",
      "2200 7473 [2200]\n",
      "2201 4379 [2201]\n",
      "2202 1003 [2202]\n",
      "2203 302 [2203]\n",
      "2204 6257 [2204]\n",
      "2205 6284 [2205]\n",
      "2206 11268 [2206]\n",
      "2207 5534 [2207]\n",
      "2208 8602 [2208]\n",
      "2209 2562 [2209]\n",
      "2210 4607 [2210]\n",
      "2211 5894 [2211]\n",
      "2212 1723 [2212]\n",
      "2213 4235 [2213]\n",
      "2214 2689 [2214]\n",
      "2215 775 [2215]\n",
      "2216 8034 [2216]\n",
      "2217 11156 [2217]\n",
      "2218 8948 [2218]\n",
      "2219 4129 [2219]\n",
      "2220 9165 [2220]\n",
      "2221 3093 [2221]\n",
      "2222 9854 [2222]\n",
      "2223 5841 [2223]\n",
      "2224 231 [2224]\n",
      "2225 2628 [2225]\n",
      "2226 9028 [2226]\n",
      "2227 11529 [2227]\n",
      "2228 130 [2228]\n",
      "2229 3999 [2229]\n",
      "2230 11465 [2230]\n",
      "2231 5053 [2231]\n",
      "2232 5617 [2232]\n",
      "2233 9233 [2233]\n",
      "2234 806 [2234]\n",
      "2235 8999 [2235]\n",
      "2236 36 [2236]\n",
      "2237 1237 [2237]\n",
      "2238 4825 [2238]\n",
      "2239 5726 [2239]\n",
      "2240 3866 [2240]\n",
      "2241 7960 [2241]\n",
      "2242 4426 [2242]\n",
      "2243 5620 [2243]\n",
      "2244 6828 [2244]\n",
      "2245 5079 [2245]\n",
      "2246 260 [2246]\n",
      "2247 6879 [2247]\n",
      "2248 6195 [2248]\n",
      "2249 5608 [2249]\n",
      "2250 618 [2250]\n",
      "2251 6899 [2251]\n",
      "2252 8552 [2252]\n",
      "2253 114 [2253]\n",
      "2254 40 [2254]\n",
      "2255 4631 [2255]\n",
      "2256 3164 [2256]\n",
      "2257 3440 [2257]\n",
      "2258 104 [2258]\n",
      "2259 11205 [2259]\n",
      "2260 3267 [2260]\n",
      "2261 3223 [2261]\n",
      "2262 745 [2262]\n",
      "2263 7507 [2263]\n",
      "2264 7141 [2264]\n",
      "2265 7664 [2265]\n",
      "2266 240 [2266]\n",
      "2267 11438 [2267]\n",
      "2268 5186 [2268]\n",
      "2269 2123 [2269]\n",
      "2270 6036 [2270]\n",
      "2271 6349 [2271]\n",
      "2272 10933 [2272]\n",
      "2273 6926 [2273]\n",
      "2274 4879 [2274]\n",
      "2275 2258 [2275]\n",
      "2276 8851 [2276]\n",
      "2277 5700 [2277]\n",
      "2278 6989 [2278]\n",
      "2279 8204 [2279]\n",
      "2280 11393 [2280]\n",
      "2281 8249 [2281]\n",
      "2282 6007 [2282]\n",
      "2283 6017 [2283]\n",
      "2284 1765 [2284]\n",
      "2285 7264 [2285]\n",
      "2286 2685 [2286]\n",
      "2287 11214 [2287]\n",
      "2288 2906 [2288]\n",
      "2289 7013 [2289]\n",
      "2290 9945 [2290]\n",
      "2291 7216 [2291]\n",
      "2292 2477 [2292]\n",
      "2293 11037 [2293]\n",
      "2294 10154 [2294]\n",
      "2295 5143 [2295]\n",
      "2296 9399 [2296]\n",
      "2297 6317 [2297]\n",
      "2298 7460 [2298]\n",
      "2299 10202 [2299]\n",
      "2300 8376 [2300]\n",
      "2301 5007 [2301]\n",
      "2302 9838 [2302]\n",
      "2303 4691 [2303]\n",
      "2304 3087 [2304]\n",
      "2305 3671 [2305]\n",
      "2306 11263 [2306]\n",
      "2307 10898 [2307]\n",
      "2308 2298 [2308]\n",
      "2309 2416 [2309]\n",
      "2310 7056 [2310]\n",
      "2311 2642 [2311]\n",
      "2312 10461 [2312]\n",
      "2313 3974 [2313]\n",
      "2314 4481 [2314]\n",
      "2315 2468 [2315]\n",
      "2316 8950 [2316]\n",
      "2317 6648 [2317]\n",
      "2318 2721 [2318]\n",
      "2319 10733 [2319]\n",
      "2320 5255 [2320]\n",
      "2321 7534 [2321]\n",
      "2322 5560 [2322]\n",
      "2323 10974 [2323]\n",
      "2324 9137 [2324]\n",
      "2325 11198 [2325]\n",
      "2326 6992 [2326]\n",
      "2327 7210 [2327]\n",
      "2328 10049 [2328]\n",
      "2329 6117 [2329]\n",
      "2330 9075 [2330]\n",
      "2331 5167 [2331]\n",
      "2332 971 [2332]\n",
      "2333 6546 [2333]\n",
      "2334 2681 [2334]\n",
      "2335 11716 [2335]\n",
      "2336 8109 [2336]\n",
      "2337 6246 [2337]\n",
      "2338 4439 [2338]\n",
      "2339 1910 [2339]\n",
      "2340 11228 [2340]\n",
      "2341 10771 [2341]\n",
      "2342 4483 [2342]\n",
      "2343 7523 [2343]\n",
      "2344 6442 [2344]\n",
      "2345 2717 [2345]\n",
      "2346 9473 [2346]\n",
      "2347 3861 [2347]\n",
      "2348 8707 [2348]\n",
      "2349 4718 [2349]\n",
      "2350 4002 [2350]\n",
      "2351 8815 [2351]\n",
      "2352 326 [2352]\n",
      "2353 11154 [2353]\n",
      "2354 4354 [2354]\n",
      "2355 10949 [2355]\n",
      "2356 6300 [2356]\n",
      "2357 10330 [2357]\n",
      "2358 5078 [2358]\n",
      "2359 7443 [2359]\n",
      "2360 7115 [2360]\n",
      "2361 3497 [2361]\n",
      "2362 9059 [2362]\n",
      "2363 4296 [2363]\n",
      "2364 6382 [2364]\n",
      "2365 2053 [2365]\n",
      "2366 1510 [2366]\n",
      "2367 9483 [2367]\n",
      "2368 10219 [2368]\n",
      "2369 5086 [2369]\n",
      "2370 3124 [2370]\n",
      "2371 553 [2371]\n",
      "2372 630 [2372]\n",
      "2373 9380 [2373]\n",
      "2374 6062 [2374]\n",
      "2375 5460 [2375]\n",
      "2376 8132 [2376]\n",
      "2377 1195 [2377]\n",
      "2378 5512 [2378]\n",
      "2379 3372 [2379]\n",
      "2380 6684 [2380]\n",
      "2381 4722 [2381]\n",
      "2382 63 [2382]\n",
      "2383 10454 [2383]\n",
      "2384 1156 [2384]\n",
      "2385 8550 [2385]\n",
      "2386 11470 [2386]\n",
      "2387 1880 [2387]\n",
      "2388 6126 [2388]\n",
      "2389 8797 [2389]\n",
      "2390 1337 [2390]\n",
      "2391 3151 [2391]\n",
      "2392 7999 [2392]\n",
      "2393 3235 [2393]\n",
      "2394 2881 [2394]\n",
      "2395 4940 [2395]\n",
      "2396 10277 [2396]\n",
      "2397 10248 [2397]\n"
     ]
    }
   ],
   "source": [
    "# part2_df['indices_pseudogroup_eval_epoch_0_val'][idx] == part2_data.dataset.indices[idx]\n",
    "# we can use this match up to create our weighted sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1365 11701  1249 ...  4940 10277 10248]\n"
     ]
    }
   ],
   "source": [
    "print(part2_data.dataset.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train new model using pseudogroup labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/thien/spurious_CUB/runs/2wkyh2tm\" target=\"_blank\">amber-totem-14</a></strong> to <a href=\"https://wandb.ai/thien/spurious_CUB\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data...\n",
      "    waterbird_complete95 = 0, forest2water2 = 0: n = 1753\n",
      "    waterbird_complete95 = 0, forest2water2 = 1: n = 96\n",
      "    waterbird_complete95 = 1, forest2water2 = 0: n = 28\n",
      "    waterbird_complete95 = 1, forest2water2 = 1: n = 521\n",
      "Validation Data...\n",
      "    waterbird_complete95 = 0, forest2water2 = 0: n = 467\n",
      "    waterbird_complete95 = 0, forest2water2 = 1: n = 466\n",
      "    waterbird_complete95 = 1, forest2water2 = 0: n = 133\n",
      "    waterbird_complete95 = 1, forest2water2 = 1: n = 133\n",
      "Test Data...\n",
      "    waterbird_complete95 = 0, forest2water2 = 0: n = 2255\n",
      "    waterbird_complete95 = 0, forest2water2 = 1: n = 2255\n",
      "    waterbird_complete95 = 1, forest2water2 = 0: n = 642\n",
      "    waterbird_complete95 = 1, forest2water2 = 1: n = 642\n",
      "Training for 51 epochs...\n",
      "\n",
      "Epoch [0]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.945  \n",
      "Average sample loss: 0.945  \n",
      "Average acc: 0.687  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1334]:\tloss = 0.150  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.945\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 828]:\tloss = 1.270  exp loss = 0.821  adjusted loss = 0.821  adv prob = 0.250000   acc = 0.536\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 322]:\tloss = 2.220  exp loss = 1.209  adjusted loss = 1.209  adv prob = 0.250000   acc = 0.366\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 716]:\tloss = 1.479  exp loss = 1.055  adjusted loss = 1.055  adv prob = 0.250000   acc = 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_0.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.358  \n",
      "Average sample loss: 0.358  \n",
      "Average acc: 0.850  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 635]:\tloss = 0.197  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.946\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 375]:\tloss = 0.311  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 0.877\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 165]:\tloss = 0.455  exp loss = 0.516  adjusted loss = 0.516  adv prob = 0.250000   acc = 0.818\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:\tloss = 0.661  exp loss = 0.658  adjusted loss = 0.658  adv prob = 0.250000   acc = 0.658\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_0.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.259  \n",
      "Average sample loss: 0.258  \n",
      "Average acc: 0.917  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.202  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.249  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.921\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.481  exp loss = 0.560  adjusted loss = 0.560  adv prob = 0.250000   acc = 0.774\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.272  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_0.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [1]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.329  \n",
      "Average sample loss: 0.329  \n",
      "Average acc: 0.874  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1353]:\tloss = 0.207  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.940\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 798]:\tloss = 0.248  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.939\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 320]:\tloss = 0.430  exp loss = 0.400  adjusted loss = 0.400  adv prob = 0.250000   acc = 0.875\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 729]:\tloss = 0.597  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_1.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.297  \n",
      "Average sample loss: 0.296  \n",
      "Average acc: 0.894  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 616]:\tloss = 0.183  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.956\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 405]:\tloss = 0.231  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.951\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 167]:\tloss = 0.427  exp loss = 0.393  adjusted loss = 0.393  adv prob = 0.250000   acc = 0.904\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 332]:\tloss = 0.523  exp loss = 0.482  adjusted loss = 0.482  adv prob = 0.250000   acc = 0.705\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_1.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.282  \n",
      "Average sample loss: 0.281  \n",
      "Average acc: 0.898  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.175  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.968\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.319  exp loss = 0.332  adjusted loss = 0.332  adv prob = 0.250000   acc = 0.873\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.564  exp loss = 0.640  adjusted loss = 0.640  adv prob = 0.250000   acc = 0.752\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.245  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_1.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [2]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.266  \n",
      "Average sample loss: 0.266  \n",
      "Average acc: 0.907  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1347]:\tloss = 0.166  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.954\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 818]:\tloss = 0.215  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.962\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 316]:\tloss = 0.402  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.902\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:\tloss = 0.452  exp loss = 0.431  adjusted loss = 0.431  adv prob = 0.250000   acc = 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_2.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.242  \n",
      "Average sample loss: 0.242  \n",
      "Average acc: 0.930  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 622]:\tloss = 0.166  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.957\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 385]:\tloss = 0.234  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.958\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 171]:\tloss = 0.360  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.895\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:\tloss = 0.329  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.868\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_2.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.278  \n",
      "Average sample loss: 0.277  \n",
      "Average acc: 0.892  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.154  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.966\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.325  exp loss = 0.336  adjusted loss = 0.336  adv prob = 0.250000   acc = 0.865\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.583  exp loss = 0.657  adjusted loss = 0.657  adv prob = 0.250000   acc = 0.744\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.246  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_2.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [3]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.228  \n",
      "Average sample loss: 0.228  \n",
      "Average acc: 0.924  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1324]:\tloss = 0.144  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.955\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 797]:\tloss = 0.182  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.969\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 335]:\tloss = 0.333  exp loss = 0.298  adjusted loss = 0.298  adv prob = 0.250000   acc = 0.925\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 744]:\tloss = 0.379  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_3.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.237  \n",
      "Average sample loss: 0.236  \n",
      "Average acc: 0.917  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 645]:\tloss = 0.146  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.961\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 406]:\tloss = 0.218  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.938\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 152]:\tloss = 0.390  exp loss = 0.342  adjusted loss = 0.342  adv prob = 0.250000   acc = 0.836\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 317]:\tloss = 0.370  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 0.839\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_3.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.267  \n",
      "Average sample loss: 0.266  \n",
      "Average acc: 0.897  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.120  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.284  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 0.886\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.694  exp loss = 0.774  adjusted loss = 0.774  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.297  exp loss = 0.268  adjusted loss = 0.268  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_3.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [4]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.209  \n",
      "Average sample loss: 0.209  \n",
      "Average acc: 0.938  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1314]:\tloss = 0.137  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.966\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 831]:\tloss = 0.170  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 304]:\tloss = 0.324  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.891\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 751]:\tloss = 0.330  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_4.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.185  \n",
      "Average sample loss: 0.185  \n",
      "Average acc: 0.960  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 655]:\tloss = 0.116  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 372]:\tloss = 0.157  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 183]:\tloss = 0.303  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.945\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 310]:\tloss = 0.295  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.903\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_4.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.274  \n",
      "Average sample loss: 0.273  \n",
      "Average acc: 0.893  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.115  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.307  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.880\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.700  exp loss = 0.779  adjusted loss = 0.779  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.293  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_4.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [5]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.184  \n",
      "Average sample loss: 0.184  \n",
      "Average acc: 0.954  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1357]:\tloss = 0.125  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.971\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 809]:\tloss = 0.147  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 326]:\tloss = 0.279  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.929\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:\tloss = 0.297  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_5.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.178  \n",
      "Average sample loss: 0.178  \n",
      "Average acc: 0.964  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 612]:\tloss = 0.123  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.967\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 394]:\tloss = 0.167  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 161]:\tloss = 0.210  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.975\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:\tloss = 0.272  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.938\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_5.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.257  \n",
      "Average sample loss: 0.256  \n",
      "Average acc: 0.902  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.073  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.221  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.910\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.900  exp loss = 0.997  adjusted loss = 0.997  adv prob = 0.250000   acc = 0.639\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.386  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.850\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_5.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [6]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.164  \n",
      "Average sample loss: 0.164  \n",
      "Average acc: 0.965  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1324]:\tloss = 0.097  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 825]:\tloss = 0.141  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 333]:\tloss = 0.247  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.958\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:\tloss = 0.274  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_6.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.170  \n",
      "Average sample loss: 0.170  \n",
      "Average acc: 0.958  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 645]:\tloss = 0.124  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 378]:\tloss = 0.118  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 154]:\tloss = 0.242  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.948\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:\tloss = 0.282  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.898\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_6.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.288  \n",
      "Average sample loss: 0.287  \n",
      "Average acc: 0.886  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.115  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.336  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.863\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.721  exp loss = 0.799  adjusted loss = 0.799  adv prob = 0.250000   acc = 0.707\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.289  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_6.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [7]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.152  \n",
      "Average sample loss: 0.152  \n",
      "Average acc: 0.973  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1320]:\tloss = 0.102  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 848]:\tloss = 0.125  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 335]:\tloss = 0.220  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:\tloss = 0.247  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_7.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.151  \n",
      "Average sample loss: 0.151  \n",
      "Average acc: 0.974  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 649]:\tloss = 0.103  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 355]:\tloss = 0.131  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 152]:\tloss = 0.226  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:\tloss = 0.224  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.959\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_7.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.282  \n",
      "Average sample loss: 0.281  \n",
      "Average acc: 0.892  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.094  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.324  exp loss = 0.325  adjusted loss = 0.325  adv prob = 0.250000   acc = 0.869\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.772  exp loss = 0.851  adjusted loss = 0.851  adv prob = 0.250000   acc = 0.707\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.298  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_7.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [8]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.146  \n",
      "Average sample loss: 0.146  \n",
      "Average acc: 0.977  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1297]:\tloss = 0.100  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 832]:\tloss = 0.129  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 319]:\tloss = 0.195  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.978\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 752]:\tloss = 0.224  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_8.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.146  \n",
      "Average sample loss: 0.146  \n",
      "Average acc: 0.965  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 672]:\tloss = 0.096  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.973\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 371]:\tloss = 0.116  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 168]:\tloss = 0.199  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 309]:\tloss = 0.260  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.913\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_8.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.283  \n",
      "Average sample loss: 0.282  \n",
      "Average acc: 0.892  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.085  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.317  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.878\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.825  exp loss = 0.903  adjusted loss = 0.903  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.318  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_8.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [9]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.145  \n",
      "Average sample loss: 0.145  \n",
      "Average acc: 0.973  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1330]:\tloss = 0.095  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 826]:\tloss = 0.116  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 304]:\tloss = 0.202  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 740]:\tloss = 0.241  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_9.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.129  \n",
      "Average sample loss: 0.130  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 639]:\tloss = 0.083  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 377]:\tloss = 0.110  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 183]:\tloss = 0.189  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 321]:\tloss = 0.209  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.956\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_9.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.313  \n",
      "Average sample loss: 0.312  \n",
      "Average acc: 0.871  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.106  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.959\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.419  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.822\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.728  exp loss = 0.791  adjusted loss = 0.791  adv prob = 0.250000   acc = 0.722\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.251  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_9.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [10]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.126  \n",
      "Average sample loss: 0.126  \n",
      "Average acc: 0.979  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1359]:\tloss = 0.087  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 793]:\tloss = 0.108  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 343]:\tloss = 0.162  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:\tloss = 0.203  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_10.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.132  \n",
      "Average sample loss: 0.131  \n",
      "Average acc: 0.979  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 610]:\tloss = 0.087  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 410]:\tloss = 0.091  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:\tloss = 0.198  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:\tloss = 0.228  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.961\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_10.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.312  \n",
      "Average sample loss: 0.312  \n",
      "Average acc: 0.872  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.104  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 0.961\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.410  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.824\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.751  exp loss = 0.812  adjusted loss = 0.812  adv prob = 0.250000   acc = 0.722\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.260  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_10.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [11]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.122  \n",
      "Average sample loss: 0.122  \n",
      "Average acc: 0.979  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1329]:\tloss = 0.085  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.981\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 811]:\tloss = 0.100  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 333]:\tloss = 0.169  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 727]:\tloss = 0.192  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_11.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.133  \n",
      "Average sample loss: 0.132  \n",
      "Average acc: 0.975  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 640]:\tloss = 0.093  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 392]:\tloss = 0.116  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 154]:\tloss = 0.150  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 334]:\tloss = 0.221  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.946\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_11.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.289  \n",
      "Average sample loss: 0.288  \n",
      "Average acc: 0.892  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.071  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.324  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.873\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.897  exp loss = 0.979  adjusted loss = 0.979  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.327  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_11.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [12]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.127  \n",
      "Average sample loss: 0.127  \n",
      "Average acc: 0.978  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1335]:\tloss = 0.083  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.981\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 802]:\tloss = 0.123  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 337]:\tloss = 0.155  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 726]:\tloss = 0.197  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_12.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.129  \n",
      "Average sample loss: 0.129  \n",
      "Average acc: 0.970  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 634]:\tloss = 0.082  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 401]:\tloss = 0.103  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 150]:\tloss = 0.171  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:\tloss = 0.230  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.934\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_12.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.293  \n",
      "Average sample loss: 0.293  \n",
      "Average acc: 0.889  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.079  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.341  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.863\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.857  exp loss = 0.918  adjusted loss = 0.918  adv prob = 0.250000   acc = 0.699\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.314  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_12.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [13]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.121  \n",
      "Average sample loss: 0.121  \n",
      "Average acc: 0.975  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1343]:\tloss = 0.081  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 793]:\tloss = 0.102  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 343]:\tloss = 0.150  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:\tloss = 0.204  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_13.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.100  \n",
      "Average sample loss: 0.100  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 626]:\tloss = 0.062  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 410]:\tloss = 0.085  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:\tloss = 0.171  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:\tloss = 0.160  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.974\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_13.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.304  \n",
      "Average sample loss: 0.303  \n",
      "Average acc: 0.883  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.079  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.360  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.854\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.884  exp loss = 0.955  adjusted loss = 0.955  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.317  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_13.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [14]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.110  \n",
      "Average sample loss: 0.110  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1298]:\tloss = 0.071  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 830]:\tloss = 0.087  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 347]:\tloss = 0.158  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.977\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 725]:\tloss = 0.182  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_14.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.108  \n",
      "Average sample loss: 0.108  \n",
      "Average acc: 0.982  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 671]:\tloss = 0.077  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 373]:\tloss = 0.088  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 140]:\tloss = 0.134  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 336]:\tloss = 0.182  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.967\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_14.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.312  \n",
      "Average sample loss: 0.311  \n",
      "Average acc: 0.880  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.080  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.393  exp loss = 0.390  adjusted loss = 0.390  adv prob = 0.250000   acc = 0.839\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.861  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.707\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.296  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_14.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [15]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.110  \n",
      "Average sample loss: 0.110  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1308]:\tloss = 0.074  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 839]:\tloss = 0.086  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 334]:\tloss = 0.138  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:\tloss = 0.189  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_15.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.101  \n",
      "Average sample loss: 0.101  \n",
      "Average acc: 0.981  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 661]:\tloss = 0.065  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 364]:\tloss = 0.086  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 153]:\tloss = 0.134  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:\tloss = 0.173  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.953\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_15.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.317  \n",
      "Average sample loss: 0.316  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.082  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.393  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.835\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.885  exp loss = 0.948  adjusted loss = 0.948  adv prob = 0.250000   acc = 0.699\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.306  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_15.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [16]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.104  \n",
      "Average sample loss: 0.104  \n",
      "Average acc: 0.983  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1321]:\tloss = 0.074  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 814]:\tloss = 0.088  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 349]:\tloss = 0.134  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 716]:\tloss = 0.166  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_16.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.103  \n",
      "Average sample loss: 0.104  \n",
      "Average acc: 0.981  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 648]:\tloss = 0.067  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 389]:\tloss = 0.083  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 138]:\tloss = 0.136  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:\tloss = 0.183  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.954\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_16.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.322  \n",
      "Average sample loss: 0.322  \n",
      "Average acc: 0.879  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.083  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.421  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.833\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.853  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.722\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.286  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_16.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [17]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.104  \n",
      "Average sample loss: 0.104  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1353]:\tloss = 0.070  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 826]:\tloss = 0.089  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 307]:\tloss = 0.122  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:\tloss = 0.179  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_17.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.096  \n",
      "Average sample loss: 0.096  \n",
      "Average acc: 0.985  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 616]:\tloss = 0.060  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 377]:\tloss = 0.072  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 180]:\tloss = 0.140  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:\tloss = 0.162  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.968\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_17.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.335  \n",
      "Average sample loss: 0.335  \n",
      "Average acc: 0.876  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.097  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.462  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.822\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.795  exp loss = 0.853  adjusted loss = 0.853  adv prob = 0.250000   acc = 0.729\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.267  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.902\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_17.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [18]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.102  \n",
      "Average sample loss: 0.102  \n",
      "Average acc: 0.983  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1345]:\tloss = 0.073  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 812]:\tloss = 0.088  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 331]:\tloss = 0.132  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:\tloss = 0.161  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_18.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.097  \n",
      "Average sample loss: 0.096  \n",
      "Average acc: 0.976  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 624]:\tloss = 0.066  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 391]:\tloss = 0.076  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 156]:\tloss = 0.131  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.968\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:\tloss = 0.159  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.960\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_18.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.312  \n",
      "Average sample loss: 0.312  \n",
      "Average acc: 0.886  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.065  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.363  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.858\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.976  exp loss = 1.041  adjusted loss = 1.041  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.338  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_18.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [19]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.088  \n",
      "Average sample loss: 0.088  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1357]:\tloss = 0.061  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 830]:\tloss = 0.066  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.996\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 313]:\tloss = 0.118  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:\tloss = 0.153  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_19.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.094  \n",
      "Average sample loss: 0.094  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 612]:\tloss = 0.060  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 373]:\tloss = 0.076  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 174]:\tloss = 0.113  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 361]:\tloss = 0.160  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.970\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_19.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.345  \n",
      "Average sample loss: 0.345  \n",
      "Average acc: 0.873  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.094  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.966\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.489  exp loss = 0.485  adjusted loss = 0.485  adv prob = 0.250000   acc = 0.813\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.812  exp loss = 0.869  adjusted loss = 0.869  adv prob = 0.250000   acc = 0.729\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.257  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.902\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_19.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [20]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.089  \n",
      "Average sample loss: 0.089  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1359]:\tloss = 0.060  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 809]:\tloss = 0.073  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 327]:\tloss = 0.115  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:\tloss = 0.151  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_20.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.091  \n",
      "Average sample loss: 0.091  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 610]:\tloss = 0.064  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 394]:\tloss = 0.079  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 160]:\tloss = 0.097  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:\tloss = 0.147  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.975\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_20.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.319  \n",
      "Average sample loss: 0.318  \n",
      "Average acc: 0.886  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.059  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.368  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.858\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.031  exp loss = 1.106  adjusted loss = 1.106  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.344  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.865\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_20.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [21]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.093  \n",
      "Average sample loss: 0.093  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1332]:\tloss = 0.070  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 822]:\tloss = 0.075  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 348]:\tloss = 0.095  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:\tloss = 0.155  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_21.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.092  \n",
      "Average sample loss: 0.092  \n",
      "Average acc: 0.984  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 637]:\tloss = 0.051  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 381]:\tloss = 0.080  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 139]:\tloss = 0.133  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:\tloss = 0.161  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.967\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_21.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.364  \n",
      "Average sample loss: 0.364  \n",
      "Average acc: 0.866  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.096  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.964\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.535  exp loss = 0.531  adjusted loss = 0.531  adv prob = 0.250000   acc = 0.794\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.823  exp loss = 0.879  adjusted loss = 0.879  adv prob = 0.250000   acc = 0.729\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.244  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.910\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_21.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [22]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.088  \n",
      "Average sample loss: 0.088  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1325]:\tloss = 0.066  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 834]:\tloss = 0.076  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 329]:\tloss = 0.091  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:\tloss = 0.142  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_22.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.081  \n",
      "Average sample loss: 0.081  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 644]:\tloss = 0.052  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 369]:\tloss = 0.059  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 158]:\tloss = 0.121  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.981\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:\tloss = 0.139  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.968\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_22.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.339  \n",
      "Average sample loss: 0.339  \n",
      "Average acc: 0.879  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.079  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.453  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.835\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.903  exp loss = 0.967  adjusted loss = 0.967  adv prob = 0.250000   acc = 0.707\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.288  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_22.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [23]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.083  \n",
      "Average sample loss: 0.083  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1351]:\tloss = 0.055  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 809]:\tloss = 0.068  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 321]:\tloss = 0.106  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:\tloss = 0.144  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_23.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.084  \n",
      "Average sample loss: 0.084  \n",
      "Average acc: 0.992  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 618]:\tloss = 0.067  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 394]:\tloss = 0.069  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 166]:\tloss = 0.097  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:\tloss = 0.126  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 0.985\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_23.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.335  \n",
      "Average sample loss: 0.335  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.066  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.418  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.843\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.998  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.324  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_23.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [24]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.083  \n",
      "Average sample loss: 0.083  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1351]:\tloss = 0.054  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 792]:\tloss = 0.066  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 336]:\tloss = 0.105  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:\tloss = 0.144  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_24.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.083  \n",
      "Average sample loss: 0.083  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 618]:\tloss = 0.065  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 411]:\tloss = 0.067  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 151]:\tloss = 0.097  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:\tloss = 0.128  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.971\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_24.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.341  \n",
      "Average sample loss: 0.342  \n",
      "Average acc: 0.878  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.079  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.454  exp loss = 0.445  adjusted loss = 0.445  adv prob = 0.250000   acc = 0.830\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.916  exp loss = 0.969  adjusted loss = 0.969  adv prob = 0.250000   acc = 0.714\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.292  exp loss = 0.268  adjusted loss = 0.268  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_24.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [25]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.081  \n",
      "Average sample loss: 0.081  \n",
      "Average acc: 0.983  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1322]:\tloss = 0.052  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 804]:\tloss = 0.061  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 335]:\tloss = 0.105  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 739]:\tloss = 0.144  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_25.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.084  \n",
      "Average sample loss: 0.084  \n",
      "Average acc: 0.985  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 647]:\tloss = 0.060  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 399]:\tloss = 0.068  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 152]:\tloss = 0.075  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 322]:\tloss = 0.158  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.963\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_25.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.328  \n",
      "Average sample loss: 0.328  \n",
      "Average acc: 0.885  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.053  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.372  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.861\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.104  exp loss = 1.179  adjusted loss = 1.179  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.362  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_25.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [26]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.076  \n",
      "Average sample loss: 0.076  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1313]:\tloss = 0.053  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 833]:\tloss = 0.060  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.996\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 328]:\tloss = 0.098  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 726]:\tloss = 0.128  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_26.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.101  \n",
      "Average sample loss: 0.101  \n",
      "Average acc: 0.978  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 656]:\tloss = 0.068  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 370]:\tloss = 0.084  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 159]:\tloss = 0.109  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:\tloss = 0.181  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.946\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_26.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.350  \n",
      "Average sample loss: 0.350  \n",
      "Average acc: 0.878  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.072  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.470  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.835\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.967  exp loss = 1.025  adjusted loss = 1.025  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.291  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.895\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_26.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [27]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.081  \n",
      "Average sample loss: 0.081  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1324]:\tloss = 0.057  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 800]:\tloss = 0.067  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 341]:\tloss = 0.104  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 735]:\tloss = 0.127  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_27.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.075  \n",
      "Average sample loss: 0.076  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 645]:\tloss = 0.039  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 403]:\tloss = 0.050  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.998\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 146]:\tloss = 0.121  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 326]:\tloss = 0.157  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.975\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_27.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.333  \n",
      "Average sample loss: 0.333  \n",
      "Average acc: 0.883  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.055  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.391  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.854\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.096  exp loss = 1.177  adjusted loss = 1.177  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.344  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_27.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [28]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.082  \n",
      "Average sample loss: 0.082  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1337]:\tloss = 0.058  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 804]:\tloss = 0.067  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 329]:\tloss = 0.109  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 730]:\tloss = 0.133  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_28.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.071  \n",
      "Average sample loss: 0.071  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 632]:\tloss = 0.055  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 399]:\tloss = 0.056  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 158]:\tloss = 0.075  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 331]:\tloss = 0.117  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.985\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_28.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.336  \n",
      "Average sample loss: 0.335  \n",
      "Average acc: 0.884  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.058  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.404  exp loss = 0.393  adjusted loss = 0.393  adv prob = 0.250000   acc = 0.856\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.064  exp loss = 1.131  adjusted loss = 1.131  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.342  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_28.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [29]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.081  \n",
      "Average sample loss: 0.081  \n",
      "Average acc: 0.985  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1352]:\tloss = 0.054  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 797]:\tloss = 0.068  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 340]:\tloss = 0.100  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:\tloss = 0.140  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_29.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.079  \n",
      "Average sample loss: 0.080  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 617]:\tloss = 0.058  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 406]:\tloss = 0.052  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.998\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 147]:\tloss = 0.095  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.980\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:\tloss = 0.142  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.971\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_29.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.346  \n",
      "Average sample loss: 0.346  \n",
      "Average acc: 0.881  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.061  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.429  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.845\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.065  exp loss = 1.131  adjusted loss = 1.131  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.336  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_29.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [30]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.078  \n",
      "Average sample loss: 0.078  \n",
      "Average acc: 0.985  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1360]:\tloss = 0.059  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 793]:\tloss = 0.066  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 323]:\tloss = 0.087  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:\tloss = 0.123  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_30.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.072  \n",
      "Average sample loss: 0.072  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 609]:\tloss = 0.032  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 410]:\tloss = 0.055  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 164]:\tloss = 0.117  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:\tloss = 0.142  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 0.967\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_30.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.366  \n",
      "Average sample loss: 0.366  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.077  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.515  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.820\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 0.943  exp loss = 0.995  adjusted loss = 0.995  adv prob = 0.250000   acc = 0.714\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.281  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.910\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_30.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [31]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.073  \n",
      "Average sample loss: 0.073  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1300]:\tloss = 0.057  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 831]:\tloss = 0.062  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 342]:\tloss = 0.082  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 727]:\tloss = 0.112  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_31.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.067  \n",
      "Average sample loss: 0.067  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 669]:\tloss = 0.038  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 372]:\tloss = 0.048  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 145]:\tloss = 0.091  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 334]:\tloss = 0.135  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.973\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_31.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.354  \n",
      "Average sample loss: 0.354  \n",
      "Average acc: 0.882  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.067  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.464  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.843\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.022  exp loss = 1.089  adjusted loss = 1.089  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.311  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_31.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [32]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.075  \n",
      "Average sample loss: 0.075  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1322]:\tloss = 0.050  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 824]:\tloss = 0.066  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 343]:\tloss = 0.089  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:\tloss = 0.126  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_32.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.066  \n",
      "Average sample loss: 0.066  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 647]:\tloss = 0.046  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 379]:\tloss = 0.048  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:\tloss = 0.075  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:\tloss = 0.122  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.966\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_32.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.354  \n",
      "Average sample loss: 0.354  \n",
      "Average acc: 0.879  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.064  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.450  exp loss = 0.440  adjusted loss = 0.440  adv prob = 0.250000   acc = 0.841\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.067  exp loss = 1.146  adjusted loss = 1.146  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.325  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_32.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [33]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.069  \n",
      "Average sample loss: 0.069  \n",
      "Average acc: 0.990  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1356]:\tloss = 0.049  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 797]:\tloss = 0.054  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 326]:\tloss = 0.074  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:\tloss = 0.119  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_33.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.068  \n",
      "Average sample loss: 0.068  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 613]:\tloss = 0.046  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 406]:\tloss = 0.063  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 161]:\tloss = 0.086  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:\tloss = 0.105  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.976\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_33.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.352  \n",
      "Average sample loss: 0.352  \n",
      "Average acc: 0.878  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.060  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.445  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.843\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.076  exp loss = 1.148  adjusted loss = 1.148  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.330  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_33.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [34]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.069  \n",
      "Average sample loss: 0.069  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1304]:\tloss = 0.041  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 825]:\tloss = 0.059  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 353]:\tloss = 0.085  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:\tloss = 0.124  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_34.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.075  \n",
      "Average sample loss: 0.074  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 665]:\tloss = 0.070  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 378]:\tloss = 0.055  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 134]:\tloss = 0.077  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:\tloss = 0.105  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.980\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_34.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.345  \n",
      "Average sample loss: 0.345  \n",
      "Average acc: 0.883  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.051  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.403  exp loss = 0.393  adjusted loss = 0.393  adv prob = 0.250000   acc = 0.856\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.160  exp loss = 1.232  adjusted loss = 1.232  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.358  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_34.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [35]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.070  \n",
      "Average sample loss: 0.070  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1358]:\tloss = 0.046  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 804]:\tloss = 0.051  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 337]:\tloss = 0.088  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:\tloss = 0.129  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_35.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.065  \n",
      "Average sample loss: 0.065  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 611]:\tloss = 0.044  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 399]:\tloss = 0.063  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 150]:\tloss = 0.087  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:\tloss = 0.094  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 0.983\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_35.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.373  \n",
      "Average sample loss: 0.373  \n",
      "Average acc: 0.871  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.066  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.970\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.504  exp loss = 0.490  adjusted loss = 0.490  adv prob = 0.250000   acc = 0.820\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.063  exp loss = 1.131  adjusted loss = 1.131  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.298  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.895\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_35.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [36]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.066  \n",
      "Average sample loss: 0.066  \n",
      "Average acc: 0.991  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1366]:\tloss = 0.045  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 789]:\tloss = 0.064  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 334]:\tloss = 0.067  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:\tloss = 0.110  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_36.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.074  \n",
      "Average sample loss: 0.076  \n",
      "Average acc: 0.984  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 603]:\tloss = 0.040  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 414]:\tloss = 0.048  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 153]:\tloss = 0.125  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:\tloss = 0.142  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.963\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_36.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.367  \n",
      "Average sample loss: 0.368  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.069  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.492  exp loss = 0.478  adjusted loss = 0.478  adv prob = 0.250000   acc = 0.826\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.034  exp loss = 1.087  adjusted loss = 1.087  adv prob = 0.250000   acc = 0.699\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.311  exp loss = 0.289  adjusted loss = 0.289  adv prob = 0.250000   acc = 0.895\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_36.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [37]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.073  \n",
      "Average sample loss: 0.073  \n",
      "Average acc: 0.985  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1333]:\tloss = 0.054  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 788]:\tloss = 0.062  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 335]:\tloss = 0.085  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 744]:\tloss = 0.115  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_37.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.075  \n",
      "Average sample loss: 0.074  \n",
      "Average acc: 0.980  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 636]:\tloss = 0.055  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 415]:\tloss = 0.071  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 152]:\tloss = 0.076  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 317]:\tloss = 0.120  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.950\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_37.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.340  \n",
      "Average sample loss: 0.340  \n",
      "Average acc: 0.890  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.039  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.983\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.337  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.880\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.310  exp loss = 1.383  adjusted loss = 1.383  adv prob = 0.250000   acc = 0.639\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.438  exp loss = 0.404  adjusted loss = 0.404  adv prob = 0.250000   acc = 0.850\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_37.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [38]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.067  \n",
      "Average sample loss: 0.067  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1345]:\tloss = 0.042  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 807]:\tloss = 0.052  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 343]:\tloss = 0.090  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:\tloss = 0.120  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_38.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.081  \n",
      "Average sample loss: 0.081  \n",
      "Average acc: 0.982  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 624]:\tloss = 0.069  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 396]:\tloss = 0.068  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:\tloss = 0.056  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:\tloss = 0.127  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.958\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_38.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.352  \n",
      "Average sample loss: 0.352  \n",
      "Average acc: 0.883  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.048  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.974\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.397  exp loss = 0.380  adjusted loss = 0.380  adv prob = 0.250000   acc = 0.858\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.232  exp loss = 1.295  adjusted loss = 1.295  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.385  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.865\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_38.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [39]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.059  \n",
      "Average sample loss: 0.059  \n",
      "Average acc: 0.991  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1326]:\tloss = 0.042  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 820]:\tloss = 0.044  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 332]:\tloss = 0.072  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:\tloss = 0.100  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_39.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.075  \n",
      "Average sample loss: 0.075  \n",
      "Average acc: 0.983  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 643]:\tloss = 0.044  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 383]:\tloss = 0.062  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 155]:\tloss = 0.080  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:\tloss = 0.145  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.956\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_39.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.370  \n",
      "Average sample loss: 0.371  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.057  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.474  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.837\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.141  exp loss = 1.208  adjusted loss = 1.208  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.336  exp loss = 0.309  adjusted loss = 0.309  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_39.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [40]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.064  \n",
      "Average sample loss: 0.064  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1336]:\tloss = 0.047  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 812]:\tloss = 0.047  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 338]:\tloss = 0.078  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:\tloss = 0.109  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_40.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.053  \n",
      "Average sample loss: 0.053  \n",
      "Average acc: 0.993  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 633]:\tloss = 0.035  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 391]:\tloss = 0.062  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 149]:\tloss = 0.056  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:\tloss = 0.073  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 0.994\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_40.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.369  \n",
      "Average sample loss: 0.369  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.060  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.471  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.837\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.133  exp loss = 1.192  adjusted loss = 1.192  adv prob = 0.250000   acc = 0.677\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.330  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_40.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [41]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.066  \n",
      "Average sample loss: 0.066  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1319]:\tloss = 0.043  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 806]:\tloss = 0.055  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 324]:\tloss = 0.078  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 751]:\tloss = 0.113  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_41.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.066  \n",
      "Average sample loss: 0.066  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 650]:\tloss = 0.050  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.985\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 397]:\tloss = 0.059  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 163]:\tloss = 0.091  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.982\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 310]:\tloss = 0.095  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.984\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_41.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.366  \n",
      "Average sample loss: 0.366  \n",
      "Average acc: 0.881  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.053  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.452  exp loss = 0.439  adjusted loss = 0.439  adv prob = 0.250000   acc = 0.845\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.185  exp loss = 1.253  adjusted loss = 1.253  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.343  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_41.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [42]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.070  \n",
      "Average sample loss: 0.070  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1343]:\tloss = 0.046  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.990\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 794]:\tloss = 0.056  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 331]:\tloss = 0.076  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 732]:\tloss = 0.125  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_42.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.059  \n",
      "Average sample loss: 0.059  \n",
      "Average acc: 0.990  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 626]:\tloss = 0.037  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 409]:\tloss = 0.041  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.998\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 156]:\tloss = 0.084  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 329]:\tloss = 0.113  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.976\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_42.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.387  \n",
      "Average sample loss: 0.387  \n",
      "Average acc: 0.876  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.067  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.539  exp loss = 0.528  adjusted loss = 0.528  adv prob = 0.250000   acc = 0.822\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.076  exp loss = 1.136  adjusted loss = 1.136  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.293  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.910\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_42.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [43]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.055  \n",
      "Average sample loss: 0.055  \n",
      "Average acc: 0.991  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1306]:\tloss = 0.043  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 822]:\tloss = 0.048  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 329]:\tloss = 0.057  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 743]:\tloss = 0.083  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_43.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.064  \n",
      "Average sample loss: 0.064  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 663]:\tloss = 0.040  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.986\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 381]:\tloss = 0.049  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 158]:\tloss = 0.072  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 318]:\tloss = 0.128  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.981\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_43.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.388  \n",
      "Average sample loss: 0.389  \n",
      "Average acc: 0.876  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.067  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.541  exp loss = 0.528  adjusted loss = 0.528  adv prob = 0.250000   acc = 0.824\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.066  exp loss = 1.119  adjusted loss = 1.119  adv prob = 0.250000   acc = 0.692\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.302  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.902\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_43.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [44]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.063  \n",
      "Average sample loss: 0.063  \n",
      "Average acc: 0.989  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1321]:\tloss = 0.045  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.989\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 823]:\tloss = 0.046  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 342]:\tloss = 0.080  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:\tloss = 0.110  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_44.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.061  \n",
      "Average sample loss: 0.061  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 648]:\tloss = 0.040  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 380]:\tloss = 0.062  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 145]:\tloss = 0.055  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:\tloss = 0.100  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.977\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_44.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.369  \n",
      "Average sample loss: 0.369  \n",
      "Average acc: 0.881  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.054  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.461  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.852\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.170  exp loss = 1.242  adjusted loss = 1.242  adv prob = 0.250000   acc = 0.662\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.347  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.880\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_44.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [45]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.054  \n",
      "Average sample loss: 0.054  \n",
      "Average acc: 0.993  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1311]:\tloss = 0.034  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 831]:\tloss = 0.053  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.996\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 328]:\tloss = 0.058  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 730]:\tloss = 0.087  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_45.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.070  \n",
      "Average sample loss: 0.070  \n",
      "Average acc: 0.987  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 658]:\tloss = 0.044  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.988\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 372]:\tloss = 0.036  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 159]:\tloss = 0.106  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.987\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 331]:\tloss = 0.141  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.976\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_45.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.371  \n",
      "Average sample loss: 0.371  \n",
      "Average acc: 0.883  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.051  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.461  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.850\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.203  exp loss = 1.274  adjusted loss = 1.274  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.349  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.887\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_45.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [46]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.066  \n",
      "Average sample loss: 0.066  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1352]:\tloss = 0.048  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.984\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 822]:\tloss = 0.056  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 317]:\tloss = 0.069  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:\tloss = 0.109  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_46.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.051  \n",
      "Average sample loss: 0.051  \n",
      "Average acc: 0.994  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 617]:\tloss = 0.033  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 381]:\tloss = 0.042  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.997\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 170]:\tloss = 0.058  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:\tloss = 0.091  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 0.986\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_46.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.375  \n",
      "Average sample loss: 0.375  \n",
      "Average acc: 0.879  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.058  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.483  exp loss = 0.466  adjusted loss = 0.466  adv prob = 0.250000   acc = 0.843\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.143  exp loss = 1.215  adjusted loss = 1.215  adv prob = 0.250000   acc = 0.684\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.338  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_46.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [47]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.062  \n",
      "Average sample loss: 0.062  \n",
      "Average acc: 0.990  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1337]:\tloss = 0.039  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 815]:\tloss = 0.048  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 324]:\tloss = 0.075  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:\tloss = 0.114  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_47.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.064  \n",
      "Average sample loss: 0.063  \n",
      "Average acc: 0.986  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 632]:\tloss = 0.051  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.979\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 388]:\tloss = 0.058  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 163]:\tloss = 0.057  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:\tloss = 0.097  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.976\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_47.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.364  \n",
      "Average sample loss: 0.364  \n",
      "Average acc: 0.884  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.046  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.976\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.416  exp loss = 0.403  adjusted loss = 0.403  adv prob = 0.250000   acc = 0.861\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.268  exp loss = 1.342  adjusted loss = 1.342  adv prob = 0.250000   acc = 0.662\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.392  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.865\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_47.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [48]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.056  \n",
      "Average sample loss: 0.056  \n",
      "Average acc: 0.990  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1344]:\tloss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 805]:\tloss = 0.047  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.998\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 338]:\tloss = 0.048  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:\tloss = 0.116  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 74/74 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_train_epoch_48.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.053  \n",
      "Average sample loss: 0.053  \n",
      "Average acc: 0.993  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 625]:\tloss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.995\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 398]:\tloss = 0.051  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.992\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 149]:\tloss = 0.074  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.993\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:\tloss = 0.072  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.991\n",
      "\n",
      "Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_val_epoch_48.csv\n",
      "logged to wandb\n",
      "Average incurred loss: 0.378  \n",
      "Average sample loss: 0.379  \n",
      "Average acc: 0.877  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:\tloss = 0.053  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.972\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:\tloss = 0.476  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.843\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:\tloss = 1.209  exp loss = 1.286  adjusted loss = 1.286  adv prob = 0.250000   acc = 0.669\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:\tloss = 0.350  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.872\n",
      "Saved myresults/CUB/waterbird_firstrun/ERM_upweight_0_epochs_51_lr_0.001_weight_decay_0.0001/retrain_part2_upweight10/output_test_epoch_48.csv\n",
      "logged to wandb\n",
      "Current lr: 0.001000\n",
      "\n",
      "\n",
      "Epoch [49]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█▉ | 49/74 [00:04<00:02, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average incurred loss: 0.061  \n",
      "Average sample loss: 0.061  \n",
      "Average acc: 0.988  \n",
      "  waterbird_complete95 = 0, forest2water2 = 0  [n = 1353]:\tloss = 0.039  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.991\n",
      "  waterbird_complete95 = 0, forest2water2 = 1  [n = 811]:\tloss = 0.048  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 0  [n = 319]:\tloss = 0.075  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.994\n",
      "  waterbird_complete95 = 1, forest2water2 = 1  [n = 717]:\tloss = 0.110  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██▏| 53/74 [00:04<00:01, 12.05it/s]"
     ]
    }
   ],
   "source": [
    "args = args_retrain_CUB\n",
    "\n",
    "RETRAIN=False  # set this to False to use old model... else we are using new model\n",
    "ONLY_LAST_LAYER=args.only_last_layer  # this this to True to only train the last layer.\n",
    "\n",
    "\"\"\"this would be in run_expt\"\"\"\n",
    "args.wandb = True  # don't set this yet...\n",
    "mode = 'w'\n",
    "if args.wandb:\n",
    "    run = wandb.init(project=f\"{args.project_name}_{args.dataset}\")\n",
    "    wandb.config.update(args)\n",
    "    \n",
    "## Initialize logs\n",
    "if not os.path.exists(args.log_dir):\n",
    "    os.makedirs(args.log_dir)\n",
    "\n",
    "logger = Logger(os.path.join(args.log_dir, \"log.txt\"), 'w')\n",
    "# Record args\n",
    "log_args(args, logger)\n",
    "\n",
    "set_seed(args.seed)\n",
    "\n",
    "# get loader and run train ERM\n",
    "loader_kwargs = {\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"num_workers\": 4,\n",
    "        \"pin_memory\": True,\n",
    "    }\n",
    "part2_rw_loader = dro_dataset.get_loader(upsampled_part2,\n",
    "                                      train=True,\n",
    "                                      reweight_groups=None,\n",
    "                                      **loader_kwargs)\n",
    "\n",
    "data = {}\n",
    "data[\"train_loader\"] = part2_rw_loader  # we train using part2 rw now!\n",
    "data[\"val_loader\"] = val_loader\n",
    "data[\"test_loader\"] = test_loader\n",
    "data[\"train_data\"] = part2_data  \n",
    "data[\"val_data\"] = val_data\n",
    "data[\"test_data\"] = test_data\n",
    "\n",
    "n_classes = train_data.n_classes\n",
    "\n",
    "log_data(data, logger)\n",
    "logger.flush()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "### INITIALIZE MODEL AND TRAIN ###\n",
    "resume = False  # not resuming yet. \n",
    "## Initialize model\n",
    "if RETRAIN:\n",
    "    model = get_model(\n",
    "        model=args.model,\n",
    "        pretrained=not args.train_from_scratch,\n",
    "        resume=resume,\n",
    "        n_classes=train_data.n_classes,\n",
    "        dataset=args.dataset,\n",
    "        log_dir=args.log_dir,\n",
    "    )\n",
    "else:\n",
    "    model = torch.load(model_path)  # this model_path is from the cell above -- fix this in code\n",
    "    \n",
    "if ONLY_LAST_LAYER:\n",
    "    assert not RETRAIN, \"is this intentional? Retraining and only training last layer --> linear classifier on random features?\"\n",
    "    # freeze everything except the last layer\n",
    "    for name, param in model.named_parameters():\n",
    "        if name not in ['fc.weight', 'fc.bias']:\n",
    "            param.requires_grad = False\n",
    "    # make sure freezing really worked\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "    \n",
    "if args.wandb:\n",
    "    wandb.watch(model)\n",
    "\n",
    "epoch_offset = 0\n",
    "\n",
    "train_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"train.csv\"),\n",
    "                                  train_data.n_groups,\n",
    "                                  mode=mode)\n",
    "val_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"val.csv\"),\n",
    "                                val_data.n_groups,\n",
    "                                mode=mode)\n",
    "test_csv_logger = CSVBatchLogger(os.path.join(args.log_dir, f\"test.csv\"),\n",
    "                                 test_data.n_groups,\n",
    "                                 mode=mode)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    criterion,\n",
    "    data,\n",
    "    logger,\n",
    "    train_csv_logger,\n",
    "    val_csv_logger,\n",
    "    test_csv_logger,\n",
    "    args,\n",
    "    epoch_offset=epoch_offset,\n",
    "    csv_name=args.fold,\n",
    "    wandb=wandb if args.wandb else None,\n",
    ")\n",
    "\n",
    "train_csv_logger.close()\n",
    "val_csv_logger.close()\n",
    "test_csv_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
